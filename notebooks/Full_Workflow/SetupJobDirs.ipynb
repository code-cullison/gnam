{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SPECFEM3D Project\n",
    "1. Unpickle events and staions\n",
    "1. Read and map moment tensors to events\n",
    "1. Prep observed station data for writing to ascii files\n",
    "1. Setup and test DATA directories and specfem3d file names\n",
    "1. Create directories and write CMTSOLUTION, STATION, STATION_ADJOINT, and trace ascii files in separate dictories for each event\n",
    "1. Pick P-arrivals\n",
    "1. Write adjoint source window parameter files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Unpickle events and stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gnam.events.gevents import gevents as gevents\n",
    "from gnam.events.gstations import gstations as gstations\n",
    "from gnam.events.munge.knmi import correct_station_depths as csd_f\n",
    "\n",
    "#Unpickle events\n",
    "print('Unpickling Events')\n",
    "f = open('../../../data_notebooks/pickled/events.pickle', 'rb')\n",
    "dill_events = pickle.load(f)\n",
    "f.close()\n",
    "    \n",
    "\n",
    "#Unpickle stations\n",
    "print('Unpickling Station Traces')\n",
    "f = open('../../../data_notebooks/pickled/straces.pickle', 'rb')\n",
    "dill_straces = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# This is kind of hokey, but it works for now.\n",
    "# Some of the stations depths do not follow the \n",
    "# 50, 100, 150, 200 meter depths -- possibly because\n",
    "# the boreholes are slanted. To correct for this,\n",
    "# a hard coded \"patch/update\" is applied. See the\n",
    "# code for details and update values.\n",
    "dill_straces.correct_stations(csd_f)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read and map moment tensors to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gnam.events.mtensors import mtensors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read moment tensors\n",
    "gf_mts = mtensors('../../../data_notebooks/data/event_moments.csv')\n",
    "    \n",
    "# get event catalog of the events withing the bounding box\n",
    "e_cat = dill_events.getIncCatalog()\n",
    "\n",
    "# This is a bit hokey, but it works. Here we update the\n",
    "# event time from the moment tensor CSV file with thouse\n",
    "# from the event catalog\n",
    "gf_mts.update_utcdatetime(e_cat)\n",
    "\n",
    "# Create a dictionary that maps moment tensors to events\n",
    "e2mt_dict = gf_mts.map_events_2_tensors(e_cat)\n",
    "e2mt_keys = e2mt_dict.keys()\n",
    "\n",
    "# Print a comparison of events to moment tensors\n",
    "for key in e2mt_keys:\n",
    "    print('UTC: event[%d][Date] = %s' %(key,e_cat[key].origins[0].time))\n",
    "    print('UTC:    MT[%d][Date] = %s' %(key,e2mt_dict[key]['Date']))\n",
    "    print('Mag: event[%d][Date] = %s' %(key,e_cat[key].magnitudes[0].mag))\n",
    "    print('Mag:    MT[%d][Date] = %s' %(key,e2mt_dict[key]['ML']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Prep observed station data for writing to ascii files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Stream\n",
    "\n",
    "#create streams and map eventid to stream\n",
    "e_stream_dict = {}\n",
    "ce_stream_dict = {}\n",
    "for ekey in e2mt_keys:\n",
    "    '''\n",
    "    e_st  = Stream()\n",
    "    e_st += dill_straces.getStreamZ(ekey,3) \n",
    "    e_st += dill_straces.getStreamZ(ekey,4) \n",
    "    e_st.resample(1000)\n",
    "    e_stream_dict[ekey] = e_st\n",
    "    '''\n",
    "    \n",
    "    #get boreholes 3 and 4 streams for the event\n",
    "    e1_st3 = dill_straces.getStream1(ekey,3)\n",
    "    e1_st4 = dill_straces.getStream1(ekey,4)\n",
    "    e2_st3 = dill_straces.getStream2(ekey,3)\n",
    "    e2_st4 = dill_straces.getStream2(ekey,4)\n",
    "    ez_st3 = dill_straces.getStreamZ(ekey,3)\n",
    "    ez_st4 = dill_straces.getStreamZ(ekey,4)\n",
    "\n",
    "    #combine component streams\n",
    "    e_st3 = e1_st3 + e2_st3 + ez_st3\n",
    "    e_st4 = e1_st4 + e2_st4 + ez_st4\n",
    "\n",
    "    #reorder streams so that each station component is contiguous\n",
    "    te_st3 = Stream()\n",
    "    te_st4 = Stream()\n",
    "\n",
    "    ns = len(ez_st3)\n",
    "    for i in range(ns):\n",
    "        te_st3 += e_st3[i+2*ns]\n",
    "        te_st3 += e_st3[i+ns]\n",
    "        te_st3 += e_st3[i]\n",
    "\n",
    "        te_st4 += e_st4[i+2*ns]\n",
    "        te_st4 += e_st4[i+ns]\n",
    "        te_st4 += e_st4[i]\n",
    "    \n",
    "    e_st3 = te_st3\n",
    "    e_st4 = te_st4\n",
    "    \n",
    "    #rotate the streams to ZNE components (obspy and the FDSN info is used)\n",
    "    inv3 = dill_straces.get_inventory(3)\n",
    "    inv4 = dill_straces.get_inventory(4)\n",
    "    e_st3.rotate(method=\"->ZNE\", inventory=inv3)\n",
    "    e_st4.rotate(method=\"->ZNE\", inventory=inv4)\n",
    "\n",
    "    #resample and map event to stream\n",
    "    e_st = e_st3 + e_st4\n",
    "    ce_st = e_st.copy() #keep a pre-resampled set for P-arrival picking (less memory)\n",
    "    e_st.resample(1000)\n",
    "    e_stream_dict[ekey] = e_st\n",
    "    ce_stream_dict[ekey] = ce_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  Setup and test DATA directories and specfem3d file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiments = []\n",
    "for ekey in e2mt_keys:\n",
    "    bkeys = dill_straces.getBoreholeKeys()\n",
    "    bh_stat_list = []\n",
    "    for bkey in bkeys:\n",
    "        bh_stat_list.append(dill_straces.getIncludedStations(ekey,bkey))\n",
    "    bh_stat_tup = tuple(bh_stat_list)   \n",
    "    exp_set = {'EKEY':ekey,'EVENT':e_cat[ekey],'TENSOR':e2mt_dict[ekey],'STATIONS':bh_stat_tup}\n",
    "    experiments.append(exp_set)\n",
    "\n",
    "dir_set_list = []\n",
    "min_eid = experiments[0]['EKEY']\n",
    "for eset in experiments:\n",
    "    eid = eset['EKEY']\n",
    "    if eid < min_eid:\n",
    "        min_eid = eid\n",
    "        \n",
    "dir_event_list = []\n",
    "for eset in experiments:\n",
    "    rdir = eset['EKEY'] - min_eid + 1\n",
    "    rdir = 'run%s' %(str(rdir).zfill(4))\n",
    "    dname = '../../../data_notebooks/SPECFEM3D/project/%s' %(rdir)\n",
    "    dir_event_list.append((eset,dname))\n",
    "    print('Experiment-%d:\\n'%(eset['EKEY']), dname)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  Create directories and write CMTSOLUTION, STATION, STATION_ADJOINT, and trace ascii files in separate dictories for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gnam.specutils.write import write_cmtsolution as spec_wcmt\n",
    "from gnam.specutils.write import write_stations as spec_ws\n",
    "import os\n",
    "\n",
    "nproc = 16\n",
    "\n",
    "# define the access rights\n",
    "access_rights = 0o755\n",
    "\n",
    "#loop over dir-set pairs\n",
    "for pair in dir_event_list[::-1]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    new_dir = dname + '/DATA'\n",
    "    print('Experiment-%d:\\n'%(eset['EKEY']), dname)\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        bkeys = dill_straces.getBoreholeKeys()\n",
    "        lxy = dill_events.getLocalEventCoord(eset['EKEY'])\n",
    "        spec_wcmt(new_dir + '/CMTSOLUTION',eset['TENSOR'],lxy[0],lxy[1])\n",
    "        spec_ws(new_dir + '/STATIONS',dill_straces,eset['EKEY'],bkeys)\n",
    "        spec_ws(new_dir + '/STATIONS_ADJOINT',dill_straces,eset['EKEY'],bkeys)\n",
    "        \n",
    "        #add links to bin and utils\n",
    "        src = '/quanta1/home/tcullison/DevGPU_specfem3d/bin'\n",
    "        dst = dname + '/bin'\n",
    "        os.symlink(src, dst)\n",
    "        src = '/quanta1/home/tcullison/DevGPU_specfem3d/utils'\n",
    "        dst = dname + '/utils'\n",
    "        os.symlink(src, dst)\n",
    "        \n",
    "    #add OUTPUT_FILES/DATABASES_MPI dirs\n",
    "    new_dir  = dname + '/OUTPUT_FILES/DATABASES_MPI'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        if eset['EKEY'] != min_eid:\n",
    "            #for k in ['Database','vp.bin','vs.bin','rho.bin']:\n",
    "            for k in ['Database','external_mesh.bin']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    mesh_fname = 'proc%s_%s' %(iproc,k)\n",
    "                    src = '../../../run0001/' + mesh_fname\n",
    "                    dst = new_dir + '/' + mesh_fname\n",
    "                    os.symlink(src, dst)\n",
    "            mesh_fname = 'surface_from_mesher.h'\n",
    "            src = '../../../run0001/OUTPUT_FILES/' + mesh_fname\n",
    "            dst = dname + '/OUTPUT_FILES/' + mesh_fname\n",
    "            os.symlink(src, dst)\n",
    "            mesh_fname = 'values_from_mesher.h'\n",
    "            src = '../../../run0001/OUTPUT_FILES/' + mesh_fname\n",
    "            dst = dname + '/OUTPUT_FILES/' + mesh_fname\n",
    "            os.symlink(src, dst)\n",
    "    \n",
    "    #add OBS dir\n",
    "    new_dir  = dname + '/OBS'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        eid = eset['EKEY']\n",
    "        e_st = e_stream_dict[eid]\n",
    "        for tr in e_st:\n",
    "            spec_pair_list = [] #time,amplitude pairs\n",
    "\n",
    "            '''\n",
    "            #Example of filename: 'NL.G094.FXX.semd'\n",
    "            tr_filename = 'NL.' + tr.stats.station + '.FXZ.semd'\n",
    "            print('filename:',tr_filename)\n",
    "\n",
    "            for it in range(tr.count()):\n",
    "                spec_pair_list.append('%E   %E\\n' %(tr.times()[it],tr.data[it]))\n",
    "\n",
    "            fqpname = new_dir + '/' + tr_filename\n",
    "            f = open(fqpname, 'w')\n",
    "            f.writelines(spec_pair_list)\n",
    "            f.close()\n",
    "            '''\n",
    "            #Example of filename: 'NL.G094.FXX.semd'\n",
    "            tr_spec_chan = '.BOO.'\n",
    "            comp_char = tr.stats.channel[2] \n",
    "            if comp_char == 'Z':\n",
    "                tr_spec_chan = '.FXZ.'\n",
    "            elif comp_char == 'E':\n",
    "                tr_spec_chan = '.FXX.'\n",
    "            elif comp_char == 'N':\n",
    "                tr_spec_chan = '.FXY.'\n",
    "            else:\n",
    "                print('Uh-oh! Spaghetti Os!')\n",
    "\n",
    "            tr_filename = 'NL.' + tr.stats.station + tr_spec_chan + 'semd'\n",
    "\n",
    "            for it in range(tr.count()):\n",
    "                spec_pair_list.append('%E   %E\\n' %(tr.times()[it],tr.data[it]))\n",
    "\n",
    "            fqpname = new_dir + '/' + tr_filename\n",
    "            f = open(fqpname, 'w')\n",
    "            f.writelines(spec_pair_list)\n",
    "            f.close()\n",
    "        \n",
    "        \n",
    "    #add FILT_OBS dir\n",
    "    new_dir  = dname + '/FILT_OBS'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add SYN dir\n",
    "    new_dir  = dname + '/SYN'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add FILT_SYN dir\n",
    "    new_dir  = dname + '/FILT_SYN'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add SEM dir\n",
    "    new_dir  = dname + '/SEM'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #if run0001 dir (this is were the model setup and update happens)\n",
    "    if eset['EKEY'] == min_eid:\n",
    "        \n",
    "        #add INPUT_KERNELS dir\n",
    "        new_dir  = dname + '/INPUT_KERNELS'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add INPUT_MODEL dir\n",
    "        new_dir  = dname + '/INPUT_MODEL'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add OUTPUT_MODEL dir\n",
    "        new_dir  = dname + '/OUTPUT_MODEL'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add OUTPUT_SUM dir\n",
    "        new_dir  = dname + '/OUTPUT_SUM'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add SMOOTH dir\n",
    "        new_dir  = dname + '/SMOOTH'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for k in ['alpha','beta','rho','hess']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    kernel_fname = 'proc%s_%s_kernel' %(iproc,k)\n",
    "                    src = './' + kernel_fname + '_smooth.bin'\n",
    "                    dst = new_dir + '/' + kernel_fname + '.bin'\n",
    "                    os.symlink(src, dst)\n",
    "        \n",
    "        #add INPUT_GRADIENT dir\n",
    "        new_dir  = dname + '/INPUT_GRADIENT'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for k in ['alpha','beta','rho','hess']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    kernel_fname = 'proc%s_%s_kernel_smooth' %(iproc,k)\n",
    "                    src = '../SMOOTH/' + kernel_fname\n",
    "                    dst = new_dir + '/' + kernel_fname + '.bin'\n",
    "                    os.symlink(src, dst)\n",
    "            \n",
    "        #add topo dir\n",
    "        new_dir  = dname + '/topo'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for i in range(nproc):\n",
    "                iproc = str(i).zfill(6)\n",
    "                ext_mesh_fname = 'proc%s_external_mesh.bin' %(iproc)\n",
    "                src = '../OUTPUT_FILES/DATABASES_MPI/' + ext_mesh_fname\n",
    "                dst = new_dir + '/' + ext_mesh_fname\n",
    "                os.symlink(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Pick P-arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from obspy.core import read\n",
    "from obspy.signal.trigger import ar_pick\n",
    "\n",
    "\n",
    "czne_st = ce_st.copy()\n",
    "\n",
    "df = czne_st[0].stats.sampling_rate\n",
    "f1 = 3.0\n",
    "f2 = 12.0\n",
    "lta_p = 1.0\n",
    "sta_p = 0.1\n",
    "lta_s = 4.0\n",
    "sta_s = 1.0\n",
    "m_p = 2\n",
    "m_s = 8\n",
    "l_p = 0.1\n",
    "l_s = 0.2\n",
    "\n",
    "p_sfudge = 0.75\n",
    "s_efudge = 0.75\n",
    "\n",
    "czne_st[0:3].filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "\n",
    "p_pick, s_pick = ar_pick(czne_st[0].data, czne_st[1].data, czne_st[2].data, df,\n",
    "                         f1, f2, lta_p, sta_p, lta_s, sta_s, m_p, m_s, l_p, l_s)\n",
    "\n",
    "#print(p_pick)\n",
    "#print(s_pick)\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(14,5))\n",
    "#print('czne_st[0]:\\n',vars(czne_st[0]))\n",
    "z_data = czne_st[0].data\n",
    "n_data = czne_st[1].data\n",
    "e_data = czne_st[2].data\n",
    "dt     = czne_st[0].stats.delta\n",
    "nt     = czne_st[0].count()\n",
    "t      = czne_st[0].times()\n",
    "#print('dt:',dt)\n",
    "#print('nt:',nt)\n",
    "#print('df:',df)\n",
    "ax.plot(t, z_data,c='black')\n",
    "ax.plot(t, n_data,c='green')\n",
    "ax.plot(t, e_data,c='orange')\n",
    "amin_z = np.min(z_data)\n",
    "amax_z = np.max(z_data)\n",
    "amin_n = np.min(n_data)\n",
    "amax_n = np.max(n_data)\n",
    "amin_e = np.min(e_data)\n",
    "amax_e = np.max(e_data)\n",
    "amin = np.min([amin_z,amin_n,amin_e])*2\n",
    "amax = np.max([amax_z,amax_n,amax_e])*2\n",
    "#print('amax:',amax)\n",
    "#print('amin:',amin)\n",
    "ax.vlines(x=p_pick, ymin=amin, ymax=amax, colors='red',linestyle='dashed')\n",
    "ax.vlines(x=p_pick-p_sfudge, ymin=amin, ymax=amax, colors='red')\n",
    "ax.vlines(x=s_pick, ymin=amin, ymax=amax, colors='blue',linestyle='dashed')\n",
    "ax.vlines(x=s_pick+s_efudge, ymin=amin, ymax=amax, colors='blue')\n",
    "\n",
    "plt.grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "plt.minorticks_on()\n",
    "plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rand\n",
    "#rand.seed(2)\n",
    "cekeys = ce_stream_dict.keys()\n",
    "min_cekey = min(cekeys)\n",
    "max_cekey = max(cekeys)\n",
    "print('min key:',min_cekey)\n",
    "print('max key:',max_cekey)\n",
    "rand_cekey = rand.randint(min_cekey, max_cekey)\n",
    "rand_cekey = min_cekey+2\n",
    "print(rand_cekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import Stream\n",
    "from obspy import Trace\n",
    "from obspy import UTCDateTime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy \n",
    "from obspy.signal.trigger import recursive_sta_lta\n",
    "from obspy.signal.trigger import plot_trigger\n",
    "\n",
    "dc_real = copy.deepcopy(ce_stream_dict[rand_cekey])\n",
    "df = ce_st[0].stats.sampling_rate\n",
    "f1 = 3.0\n",
    "f2 = 18.0\n",
    "lta_p = 1.5\n",
    "sta_p = 0.5\n",
    "lta_s = 2\n",
    "sta_s = 0.5\n",
    "m_p = 8\n",
    "m_s = 8\n",
    "l_p = 0.5\n",
    "l_s = 0.5\n",
    "\n",
    "p_trig_pad = 0.75\n",
    "s_trig_pad = 0.75\n",
    "\n",
    "dc_real.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "\n",
    "plt_h = 2\n",
    "plt_w = 14\n",
    "ntrace = len(dc_real)//3\n",
    "plt_scale = int(1*len(dc_real[:3*ntrace:3]))\n",
    "fig, ax = plt.subplots(plt_scale,figsize=(plt_w,plt_h*plt_scale))\n",
    "fig.tight_layout()\n",
    "zshft = int(0)\n",
    "nshft = int(1)\n",
    "eshft = int(2)\n",
    "shft = zshft\n",
    "triggers = np.zeros((ntrace,4))\n",
    "trig_dict = {}\n",
    "for i in range(len(dc_real[:3*ntrace:3])):\n",
    "    \n",
    "    #dc_real[shft+i*3].filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "    \n",
    "    #real_data = dc_real[shft+i*3].data\n",
    "    \n",
    "    dt     = dc_real[i*3].stats.delta\n",
    "    nt     = dc_real[i*3].count()\n",
    "    t      = dc_real[i*3].times()\n",
    "    \n",
    "    p_0, s_0 = ar_pick(dc_real[i*3].data, dc_real[i*3+1].data, dc_real[i*3+2].data, df, \n",
    "                       f1, f2, lta_p, sta_p, lta_s, sta_s, m_p, m_s, l_p, l_s)\n",
    "    \n",
    "    if s_0 < p_0:\n",
    "        s_0 = 2*p_0\n",
    "        \n",
    "    #s_0 = 2*p_0\n",
    "    #p_0 = 0.5*s_0\n",
    "    \n",
    "    # leave 0.5 sec for tapper -- this is just a guess\n",
    "    p_trig = p_0 - p_trig_pad\n",
    "    if p_trig < 0.5:\n",
    "        p_trig = 0.5\n",
    "    s_trig = s_0 + s_trig_pad\n",
    "    if nt*dt - 0.5 <= s_trig:\n",
    "        s_trig = nt*dt - 0.5\n",
    "        \n",
    "    triggers[i,0] = p_trig\n",
    "    triggers[i,1] = p_0\n",
    "    triggers[i,2] = s_0\n",
    "    triggers[i,3] = s_trig\n",
    "    trig_dict[dc_real[shft+i*3].stats.station] = np.array(triggers[i,:])\n",
    "    \n",
    "    ax[i].plot(t, dc_real[i*3].data,c='black',zorder=2)\n",
    "    ax[i].plot(t, dc_real[i*3+1],c='green',zorder=1)\n",
    "    ax[i].plot(t, dc_real[i*3+2],c='orange',zorder=0)\n",
    "    \n",
    "    amin = np.min(dc_real[i*3].data)\n",
    "    amin = np.min(np.array([amin,np.min(dc_real[i*3+1].data)]))\n",
    "    amin = np.min(np.array([amin,np.min(dc_real[i*3+2].data)]))\n",
    "    amax = np.max(dc_real[i*3].data)\n",
    "    amax = np.max(np.array([amax,np.max(dc_real[i*3+1].data)]))\n",
    "    amax = np.max(np.array([amax,np.max(dc_real[i*3+2].data)]))\n",
    "    ax[i].vlines(x=p_0, ymin=amin, ymax=amax, colors='red',linestyle='dashed')\n",
    "    ax[i].vlines(x=p_trig, ymin=amin, ymax=amax, colors='red')\n",
    "    ax[i].vlines(x=s_0, ymin=amin, ymax=amax, colors='blue',linestyle='dashed')\n",
    "    ax[i].vlines(x=s_trig, ymin=amin, ymax=amax, colors='blue')\n",
    "    \n",
    "    rstation = dc_real[i*3].stats.station\n",
    "    rstation += '.' + dc_real[shft+i*3].stats.channel\n",
    "    \n",
    "    overlay_title = 'Station:' + str(rstation)\n",
    "    ax[i].set_title(overlay_title)\n",
    "    \n",
    "    ax[i].grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "    ax[i].minorticks_on()\n",
    "    ax[i].grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Write adjoint source window parameter files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
