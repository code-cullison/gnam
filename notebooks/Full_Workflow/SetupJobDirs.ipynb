{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SPECFEM3D Project\n",
    "1. Unpickle events and staions\n",
    "1. Read and map moment tensors to events\n",
    "1. Prep observed station data for writing to ascii files\n",
    "1. Setup and test DATA directories and specfem3d file names\n",
    "1. Create directories and write CMTSOLUTION, STATION, STATION_ADJOINT, and trace ascii files in separate dictories for each event\n",
    "1. Test P-arrival pick on one trace\n",
    "1. Plot p-arrivals for all traces of a chosen event\n",
    "1. Create p-arriavls (trigger) dictionary for all events\n",
    "1. Write adjoint source window parameter files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Unpickle events and stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gnam.events.gevents import gevents as gevents\n",
    "from gnam.events.gstations import gstations as gstations\n",
    "from gnam.events.munge.knmi import correct_station_depths as csd_f\n",
    "\n",
    "data_root_dir = '../../../data_notebooks'\n",
    "\n",
    "#Unpickle events\n",
    "print('Unpickling Events')\n",
    "f = open('../../../data_notebooks/pickled/events.pickle', 'rb')\n",
    "dill_events = pickle.load(f)\n",
    "f.close()\n",
    "    \n",
    "\n",
    "#Unpickle stations\n",
    "print('Unpickling Station Traces')\n",
    "f = open('../../../data_notebooks/pickled/straces.pickle', 'rb')\n",
    "dill_straces = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# This is kind of hokey, but it works for now.\n",
    "# Some of the stations depths do not follow the \n",
    "# 50, 100, 150, 200 meter depths -- possibly because\n",
    "# the boreholes are slanted. To correct for this,\n",
    "# a hard coded \"patch/update\" is applied. See the\n",
    "# code for details and update values.\n",
    "dill_straces.correct_stations(csd_f)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read and map moment tensors to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gnam.events.mtensors import mtensors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read moment tensors\n",
    "gf_mts = mtensors('../../../data_notebooks/data/event_moments.csv')\n",
    "    \n",
    "# get event catalog of the events withing the bounding box\n",
    "e_cat = dill_events.getIncCatalog()\n",
    "\n",
    "# This is a bit hokey, but it works. Here we update the\n",
    "# event time from the moment tensor CSV file with thouse\n",
    "# from the event catalog\n",
    "gf_mts.update_utcdatetime(e_cat)\n",
    "\n",
    "# Create a dictionary that maps moment tensors to events\n",
    "e2mt_dict = gf_mts.map_events_2_tensors(e_cat)\n",
    "e2mt_keys = e2mt_dict.keys()\n",
    "\n",
    "# Print a comparison of events to moment tensors\n",
    "for key in e2mt_keys:\n",
    "    print('UTC: event[%d][Date] = %s' %(key,e_cat[key].origins[0].time))\n",
    "    print('UTC:    MT[%d][Date] = %s' %(key,e2mt_dict[key]['Date']))\n",
    "    print('Mag: event[%d][Date] = %s' %(key,e_cat[key].magnitudes[0].mag))\n",
    "    print('Mag:    MT[%d][Date] = %s' %(key,e2mt_dict[key]['ML']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Prep observed station data for writing to ascii files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Stream\n",
    "\n",
    "#create streams and map eventid to stream\n",
    "e_stream_dict = {}\n",
    "ce_stream_dict = {}\n",
    "for ekey in e2mt_keys:\n",
    "    '''\n",
    "    e_st  = Stream()\n",
    "    e_st += dill_straces.getStreamZ(ekey,3) \n",
    "    e_st += dill_straces.getStreamZ(ekey,4) \n",
    "    e_st.resample(1000)\n",
    "    e_stream_dict[ekey] = e_st\n",
    "    '''\n",
    "    \n",
    "    #get boreholes 3 and 4 streams for the event\n",
    "    e1_st3 = dill_straces.getStream1(ekey,3)\n",
    "    e1_st4 = dill_straces.getStream1(ekey,4)\n",
    "    e2_st3 = dill_straces.getStream2(ekey,3)\n",
    "    e2_st4 = dill_straces.getStream2(ekey,4)\n",
    "    ez_st3 = dill_straces.getStreamZ(ekey,3)\n",
    "    ez_st4 = dill_straces.getStreamZ(ekey,4)\n",
    "\n",
    "    #combine component streams\n",
    "    e_st3 = e1_st3 + e2_st3 + ez_st3\n",
    "    e_st4 = e1_st4 + e2_st4 + ez_st4\n",
    "\n",
    "    #reorder streams so that each station component is contiguous\n",
    "    te_st3 = Stream()\n",
    "    te_st4 = Stream()\n",
    "\n",
    "    ns = len(ez_st3)\n",
    "    for i in range(ns):\n",
    "        te_st3 += e_st3[i+2*ns]\n",
    "        te_st3 += e_st3[i+ns]\n",
    "        te_st3 += e_st3[i]\n",
    "\n",
    "        te_st4 += e_st4[i+2*ns]\n",
    "        te_st4 += e_st4[i+ns]\n",
    "        te_st4 += e_st4[i]\n",
    "    \n",
    "    e_st3 = te_st3\n",
    "    e_st4 = te_st4\n",
    "    \n",
    "    #rotate the streams to ZNE components (obspy and the FDSN info is used)\n",
    "    inv3 = dill_straces.get_inventory(3)\n",
    "    inv4 = dill_straces.get_inventory(4)\n",
    "    e_st3.rotate(method=\"->ZNE\", inventory=inv3)\n",
    "    e_st4.rotate(method=\"->ZNE\", inventory=inv4)\n",
    "\n",
    "    #resample and map event to stream\n",
    "    e_st = e_st3 + e_st4\n",
    "    ce_st = e_st.copy() #keep a pre-resampled set for P-arrival picking (less memory)\n",
    "    #e_st.resample(1000) #better to resample while iterating. \n",
    "    e_stream_dict[ekey] = e_st\n",
    "    ce_stream_dict[ekey] = ce_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  Setup and test DATA directories and specfem3d file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiments = []\n",
    "for ekey in e2mt_keys:\n",
    "    bkeys = dill_straces.getBoreholeKeys()\n",
    "    bh_stat_list = []\n",
    "    for bkey in bkeys:\n",
    "        bh_stat_list.append(dill_straces.getIncludedStations(ekey,bkey))\n",
    "    bh_stat_tup = tuple(bh_stat_list)   \n",
    "    exp_set = {'EKEY':ekey,'EVENT':e_cat[ekey],'TENSOR':e2mt_dict[ekey],'STATIONS':bh_stat_tup}\n",
    "    experiments.append(exp_set)\n",
    "\n",
    "dir_set_list = []\n",
    "min_eid = experiments[0]['EKEY']\n",
    "for eset in experiments:\n",
    "    eid = eset['EKEY']\n",
    "    if eid < min_eid:\n",
    "        min_eid = eid\n",
    "        \n",
    "dir_event_list = []\n",
    "for eset in experiments:\n",
    "    rdir = eset['EKEY'] - min_eid + 1\n",
    "    rdir = 'run%s' %(str(rdir).zfill(4))\n",
    "    dname = data_root_dir + '/SPECFEM3D/project/%s' %(rdir)\n",
    "    dir_event_list.append((eset,dname))\n",
    "    print('Experiment-%d:\\n'%(eset['EKEY']), dname)\n",
    "    print()\n",
    "dir_event_list = dir_event_list[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  Create directories and write CMTSOLUTION, STATION, STATION_ADJOINT, and trace ascii files in separate dictories for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = 3 #last event (really it's: en-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gnam.specutils.write import write_cmtsolution as spec_wcmt\n",
    "from gnam.specutils.write import write_stations as spec_ws\n",
    "from gnam.specutils.write import write_stream_2_spec_ascii as spec_wst2a\n",
    "import os\n",
    "\n",
    "nproc = 16\n",
    "\n",
    "# define the access rights\n",
    "access_rights = 0o755\n",
    "\n",
    "#loop over dir-set pairs\n",
    "for pair in dir_event_list[0:en]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    new_dir = dname + '/DATA'\n",
    "    print('Experiment-%d:\\n'%(eset['EKEY']), dname)\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        bkeys = dill_straces.getBoreholeKeys()\n",
    "        lxy = dill_events.getLocalEventCoord(eset['EKEY'])\n",
    "        spec_wcmt(new_dir + '/CMTSOLUTION',eset['TENSOR'],lxy[0],lxy[1])\n",
    "        spec_ws(new_dir + '/STATIONS',dill_straces,eset['EKEY'],bkeys)\n",
    "        spec_ws(new_dir + '/STATIONS_ADJOINT',dill_straces,eset['EKEY'],bkeys)\n",
    "        \n",
    "        #add links to bin and utils\n",
    "        src = '/quanta1/home/tcullison/DevGPU_specfem3d/bin'\n",
    "        dst = dname + '/bin'\n",
    "        os.symlink(src, dst)\n",
    "        src = '/quanta1/home/tcullison/DevGPU_specfem3d/utils'\n",
    "        dst = dname + '/utils'\n",
    "        os.symlink(src, dst)\n",
    "        \n",
    "    #add OUTPUT_FILES/DATABASES_MPI dirs\n",
    "    new_dir  = dname + '/OUTPUT_FILES/DATABASES_MPI'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        if eset['EKEY'] != min_eid:\n",
    "            #for k in ['Database','vp.bin','vs.bin','rho.bin']:\n",
    "            for k in ['Database','external_mesh.bin']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    mesh_fname = 'proc%s_%s' %(iproc,k)\n",
    "                    src = '../../../run0001/OUTPUT_FILES/DATABASES_MPI' + mesh_fname\n",
    "                    dst = new_dir + '/' + mesh_fname\n",
    "                    os.symlink(src, dst)\n",
    "            mesh_fname = 'surface_from_mesher.h'\n",
    "            src = '../../../run0001/OUTPUT_FILES/' + mesh_fname\n",
    "            dst = dname + '/OUTPUT_FILES/' + mesh_fname\n",
    "            os.symlink(src, dst)\n",
    "            mesh_fname = 'values_from_mesher.h'\n",
    "            src = '../../run0001/OUTPUT_FILES/' + mesh_fname\n",
    "            dst = dname + '/OUTPUT_FILES/' + mesh_fname\n",
    "            os.symlink(src, dst)\n",
    "    \n",
    "    #add OBS dir\n",
    "    new_dir  = dname + '/OBS'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        eid = eset['EKEY']\n",
    "        e_st = e_stream_dict[eid]\n",
    "        '''\n",
    "        for tr in e_st:\n",
    "            spec_pair_list = [] #time,amplitude pairs\n",
    "\n",
    "            #Example of filename: 'NL.G094.FXX.semd'\n",
    "            tr_filename = 'NL.' + tr.stats.station + '.FXZ.semd'\n",
    "            print('filename:',tr_filename)\n",
    "\n",
    "            for it in range(tr.count()):\n",
    "                spec_pair_list.append('%E   %E\\n' %(tr.times()[it],tr.data[it]))\n",
    "\n",
    "            fqpname = new_dir + '/' + tr_filename\n",
    "            f = open(fqpname, 'w')\n",
    "            f.writelines(spec_pair_list)\n",
    "            f.close()\n",
    "            #Example of filename: 'NL.G094.FXX.semd'\n",
    "            tr_spec_chan = '.BOO.'\n",
    "            comp_char = tr.stats.channel[2] \n",
    "            if comp_char == 'Z':\n",
    "                tr_spec_chan = '.FXZ.'\n",
    "            elif comp_char == 'E':\n",
    "                tr_spec_chan = '.FXX.'\n",
    "            elif comp_char == 'N':\n",
    "                tr_spec_chan = '.FXY.'\n",
    "            else:\n",
    "                print('Uh-oh! Spaghetti Os!')\n",
    "\n",
    "            tr_filename = 'NL.' + tr.stats.station + tr_spec_chan + 'semd'\n",
    "\n",
    "            for it in range(tr.count()):\n",
    "                spec_pair_list.append('%E   %E\\n' %(tr.times()[it],tr.data[it]))\n",
    "\n",
    "            fqpname = new_dir + '/' + tr_filename\n",
    "            f = open(fqpname, 'w')\n",
    "            f.writelines(spec_pair_list)\n",
    "            f.close()\n",
    "        '''\n",
    "        #write specfem3d ascii files \n",
    "        spec_wst2a(e_st,new_dir,is_zne=True) \n",
    "        \n",
    "        \n",
    "    #add FILT_OBS dir\n",
    "    new_dir  = dname + '/FILT_OBS'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add SYN dir\n",
    "    new_dir  = dname + '/SYN'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add FILT_SYN dir\n",
    "    new_dir  = dname + '/FILT_SYN'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add SEM dir\n",
    "    new_dir  = dname + '/SEM'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #if run0001 dir (this is were the model setup and update happens)\n",
    "    if eset['EKEY'] == min_eid:\n",
    "        \n",
    "        #add INPUT_KERNELS dir\n",
    "        new_dir  = dname + '/INPUT_KERNELS'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add INPUT_MODEL dir\n",
    "        new_dir  = dname + '/INPUT_MODEL'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add OUTPUT_MODEL dir\n",
    "        new_dir  = dname + '/OUTPUT_MODEL'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add OUTPUT_SUM dir\n",
    "        new_dir  = dname + '/OUTPUT_SUM'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add SMOOTH dir\n",
    "        new_dir  = dname + '/SMOOTH'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for k in ['alpha','beta','rho','hess']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    kernel_fname = 'proc%s_%s_kernel' %(iproc,k)\n",
    "                    src = './' + kernel_fname + '_smooth.bin'\n",
    "                    dst = new_dir + '/' + kernel_fname + '.bin'\n",
    "                    os.symlink(src, dst)\n",
    "        \n",
    "        #add INPUT_GRADIENT dir\n",
    "        new_dir  = dname + '/INPUT_GRADIENT'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for k in ['alpha','beta','rho','hess']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    kernel_fname = 'proc%s_%s_kernel_smooth' %(iproc,k)\n",
    "                    src = '../SMOOTH/' + kernel_fname + '.bin'\n",
    "                    dst = new_dir + '/' + kernel_fname + '.bin'\n",
    "                    os.symlink(src, dst)\n",
    "            \n",
    "        #add topo dir\n",
    "        new_dir  = dname + '/topo'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for i in range(nproc):\n",
    "                iproc = str(i).zfill(6)\n",
    "                ext_mesh_fname = 'proc%s_external_mesh.bin' %(iproc)\n",
    "                src = '../OUTPUT_FILES/DATABASES_MPI/' + ext_mesh_fname\n",
    "                dst = new_dir + '/' + ext_mesh_fname\n",
    "                os.symlink(src, dst)\n",
    "                \n",
    "        #add COMBINE dir (empty)\n",
    "        new_dir  = dname + '/COMBINE'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test P-arrival pick on one trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from obspy.core import read\n",
    "from obspy.signal.trigger import ar_pick\n",
    "\n",
    "\n",
    "czne_st = ce_st.copy()\n",
    "\n",
    "df = czne_st[0].stats.sampling_rate\n",
    "f1 = 3.0\n",
    "f2 = 12.0\n",
    "lta_p = 1.0\n",
    "sta_p = 0.1\n",
    "lta_s = 4.0\n",
    "sta_s = 1.0\n",
    "m_p = 2\n",
    "m_s = 8\n",
    "l_p = 0.1\n",
    "l_s = 0.2\n",
    "\n",
    "p_sfudge = 0.75\n",
    "s_efudge = 0.75\n",
    "\n",
    "czne_st[0:3].filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "\n",
    "p_pick, s_pick = ar_pick(czne_st[0].data, czne_st[1].data, czne_st[2].data, df,\n",
    "                         f1, f2, lta_p, sta_p, lta_s, sta_s, m_p, m_s, l_p, l_s)\n",
    "\n",
    "#print(p_pick)\n",
    "#print(s_pick)\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(14,5))\n",
    "#print('czne_st[0]:\\n',vars(czne_st[0]))\n",
    "z_data = czne_st[0].data\n",
    "n_data = czne_st[1].data\n",
    "e_data = czne_st[2].data\n",
    "dt     = czne_st[0].stats.delta\n",
    "nt     = czne_st[0].count()\n",
    "t      = czne_st[0].times()\n",
    "#print('dt:',dt)\n",
    "#print('nt:',nt)\n",
    "#print('df:',df)\n",
    "ax.plot(t, z_data,c='black')\n",
    "ax.plot(t, n_data,c='green')\n",
    "ax.plot(t, e_data,c='orange')\n",
    "amin_z = np.min(z_data)\n",
    "amax_z = np.max(z_data)\n",
    "amin_n = np.min(n_data)\n",
    "amax_n = np.max(n_data)\n",
    "amin_e = np.min(e_data)\n",
    "amax_e = np.max(e_data)\n",
    "amin = np.min([amin_z,amin_n,amin_e])*2\n",
    "amax = np.max([amax_z,amax_n,amax_e])*2\n",
    "#print('amax:',amax)\n",
    "#print('amin:',amin)\n",
    "ax.vlines(x=p_pick, ymin=amin, ymax=amax, colors='red',linestyle='dashed')\n",
    "ax.vlines(x=p_pick-p_sfudge, ymin=amin, ymax=amax, colors='red')\n",
    "ax.vlines(x=s_pick, ymin=amin, ymax=amax, colors='blue',linestyle='dashed')\n",
    "ax.vlines(x=s_pick+s_efudge, ymin=amin, ymax=amax, colors='blue')\n",
    "\n",
    "plt.grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "plt.minorticks_on()\n",
    "plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Plot p-arrivals for all traces of a chosen event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose event between min and max ekey (some events don't have inverted moment tensors yet)\n",
    "import numpy.random as rand\n",
    "#rand.seed(2)\n",
    "cekeys = ce_stream_dict.keys()\n",
    "min_cekey = min(cekeys)\n",
    "max_cekey = max(cekeys)\n",
    "print('min key:',min_cekey)\n",
    "print('max key:',max_cekey)\n",
    "rand_cekey = rand.randint(min_cekey, max_cekey)\n",
    "#rand_cekey = min_cekey\n",
    "rand_cekey = 4\n",
    "print(rand_cekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the picks on the trances for the chosen event.\n",
    "import obspy\n",
    "from obspy import Stream\n",
    "from obspy import Trace\n",
    "from obspy import UTCDateTime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy \n",
    "from obspy.signal.trigger import recursive_sta_lta\n",
    "from obspy.signal.trigger import plot_trigger\n",
    "\n",
    "dc_real = copy.deepcopy(ce_stream_dict[rand_cekey])\n",
    "df = ce_st[0].stats.sampling_rate\n",
    "f1 = 3.0\n",
    "f2 = 18.0\n",
    "lta_p = 1.5\n",
    "sta_p = 0.5\n",
    "lta_s = 2\n",
    "sta_s = 0.5\n",
    "m_p = 8\n",
    "m_s = 8\n",
    "l_p = 0.5\n",
    "l_s = 0.5\n",
    "\n",
    "p_trig_pad = 0.75\n",
    "s_trig_pad = 0.75\n",
    "\n",
    "dc_real.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "\n",
    "plt_h = 2\n",
    "plt_w = 14\n",
    "ntrace = len(dc_real)//3\n",
    "plt_scale = int(1*len(dc_real[:3*ntrace:3]))\n",
    "fig, ax = plt.subplots(plt_scale,figsize=(plt_w,plt_h*plt_scale))\n",
    "fig.tight_layout()\n",
    "zshft = int(0)\n",
    "nshft = int(1)\n",
    "eshft = int(2)\n",
    "shft = zshft\n",
    "triggers = np.zeros((ntrace,4))\n",
    "trig_dict = {}\n",
    "for i in range(len(dc_real[:3*ntrace:3])):\n",
    "    \n",
    "    #dc_real[shft+i*3].filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "    \n",
    "    #real_data = dc_real[shft+i*3].data\n",
    "    \n",
    "    dt     = dc_real[i*3].stats.delta\n",
    "    nt     = dc_real[i*3].count()\n",
    "    t      = dc_real[i*3].times()\n",
    "    \n",
    "    p_0, s_0 = ar_pick(dc_real[i*3].data, dc_real[i*3+1].data, dc_real[i*3+2].data, df, \n",
    "                       f1, f2, lta_p, sta_p, lta_s, sta_s, m_p, m_s, l_p, l_s)\n",
    "    \n",
    "    \n",
    "    if s_0 < p_0:\n",
    "        s_0 = 2.1*p_0\n",
    "    if (s_0 - p_0) < 2.0:\n",
    "        s_0 = p_0 + 2.0\n",
    "    assert 2.0 <= (s_0 - p_0)\n",
    "        \n",
    "    #if the padded p-pick is less then zero, set to zero\n",
    "    p_trig = p_0 - p_trig_pad\n",
    "    if p_trig < 0.0:\n",
    "        p_trig = 0.0\n",
    "    #if the padded s-pick is greater than the last time sample, set to the last sample\n",
    "    s_trig = s_0 + s_trig_pad\n",
    "    if t[-1] <= s_trig:\n",
    "        s_trig = t[-1]\n",
    "        \n",
    "    triggers[i,0] = p_trig\n",
    "    triggers[i,1] = p_0\n",
    "    triggers[i,2] = s_0\n",
    "    triggers[i,3] = s_trig\n",
    "    trig_dict[dc_real[shft+i*3].stats.station] = np.array(triggers[i,:])\n",
    "    \n",
    "    ax[i].plot(t, dc_real[i*3].data,c='black',zorder=2)\n",
    "    ax[i].plot(t, dc_real[i*3+1],c='green',zorder=1)\n",
    "    ax[i].plot(t, dc_real[i*3+2],c='orange',zorder=0)\n",
    "    \n",
    "    amin = np.min(dc_real[i*3].data)\n",
    "    amin = np.min(np.array([amin,np.min(dc_real[i*3+1].data)]))\n",
    "    amin = np.min(np.array([amin,np.min(dc_real[i*3+2].data)]))\n",
    "    amax = np.max(dc_real[i*3].data)\n",
    "    amax = np.max(np.array([amax,np.max(dc_real[i*3+1].data)]))\n",
    "    amax = np.max(np.array([amax,np.max(dc_real[i*3+2].data)]))\n",
    "    ax[i].vlines(x=p_0, ymin=amin, ymax=amax, colors='red',linestyle='dashed')\n",
    "    ax[i].vlines(x=p_trig, ymin=amin, ymax=amax, colors='red')\n",
    "    ax[i].vlines(x=s_0, ymin=amin, ymax=amax, colors='blue',linestyle='dashed')\n",
    "    ax[i].vlines(x=s_trig, ymin=amin, ymax=amax, colors='blue')\n",
    "    \n",
    "    rstation = dc_real[i*3].stats.station\n",
    "    rstation += '.' + dc_real[shft+i*3].stats.channel\n",
    "    \n",
    "    overlay_title = 'Station:' + str(rstation)\n",
    "    ax[i].set_title(overlay_title)\n",
    "    \n",
    "    ax[i].grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "    ax[i].minorticks_on()\n",
    "    ax[i].grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create p-arriavls (trigger) dictionary for all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_trigger_dict = {}\n",
    "for pair in dir_event_list[0:en]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    eid = eset['EKEY']\n",
    "    trig_dict = {}\n",
    "    \n",
    "    '''\n",
    "    #all of this should be set in code cell above\n",
    "    df = ce_st[0].stats.sampling_rate\n",
    "    f1 = 3.0\n",
    "    f2 = 18.0\n",
    "    lta_p = 1.5\n",
    "    sta_p = 0.5\n",
    "    lta_s = 2\n",
    "    sta_s = 0.5\n",
    "    m_p = 8\n",
    "    m_s = 8\n",
    "    l_p = 0.5\n",
    "    l_s = 0.5\n",
    "\n",
    "    p_trig_pad = 0.75\n",
    "    s_trig_pad = 0.75\n",
    "    '''\n",
    "\n",
    "    #make copy so that it can be filtered to a good band for picking\n",
    "    dc_real = copy.deepcopy(ce_stream_dict[eid]) \n",
    "    \n",
    "    dc_real.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "\n",
    "    ntrace = len(dc_real)//3\n",
    "    triggers = np.zeros((ntrace,4))\n",
    "    for i in range(len(dc_real[:3*ntrace:3])):\n",
    "\n",
    "        dt     = dc_real[i*3].stats.delta\n",
    "        nt     = dc_real[i*3].count()\n",
    "        t      = dc_real[i*3].times()\n",
    "\n",
    "        p_0, s_0 = ar_pick(dc_real[i*3].data, dc_real[i*3+1].data, dc_real[i*3+2].data, df, \n",
    "                           f1, f2, lta_p, sta_p, lta_s, sta_s, m_p, m_s, l_p, l_s)\n",
    "\n",
    "        if s_0 < p_0:\n",
    "            s_0 = 2.1*p_0\n",
    "        s_0 = 2.1*p_0\n",
    "        if (s_0 - p_0) < 2.0:\n",
    "            s_0 = p_0 + 2.0\n",
    "        assert 2.0 <= (s_0 - p_0)\n",
    "\n",
    "\n",
    "        #if the padded p-pick is less then zero, set to zero\n",
    "        p_trig = p_0 - p_trig_pad\n",
    "        if p_trig < 0.0:\n",
    "            p_trig = 0.0\n",
    "        #if the padded s-pick is greater than the last time sample, set to the last sample\n",
    "        s_trig = s_0 + s_trig_pad\n",
    "        if t[-1] <= s_trig:\n",
    "            s_trig = t[-1]\n",
    "\n",
    "        triggers[i,0] = p_trig\n",
    "        triggers[i,1] = p_0\n",
    "        triggers[i,2] = s_0\n",
    "        triggers[i,3] = s_trig\n",
    "        trig_dict[dc_real[i*3].stats.station] = np.array(triggers[i,:])\n",
    "        \n",
    "    #end sloop over station (and component) traces\n",
    "        \n",
    "    event_trigger_dict[eid] = trig_dict\n",
    "    \n",
    "#end loop over events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Write adjoint source window parameter files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import Stream\n",
    "from obspy import Trace\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "\n",
    "#loop over dir-set pairs\n",
    "for pair in dir_event_list[0:en]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    eid = eset['EKEY']\n",
    "    trig_dict = event_trigger_dict[eid]\n",
    "    \n",
    "    t1 = 2\n",
    "    for key in trig_dict:\n",
    "\n",
    "        tr_filename = 'NL.' + key + '.window'\n",
    "\n",
    "        p_trig = trig_dict[key][0]\n",
    "        p0     = trig_dict[key][1]\n",
    "        s0     = trig_dict[key][2]\n",
    "        s_trig = trig_dict[key][3]\n",
    "        str_t0 = 'T0 = %.3f\\n' %(p_trig)\n",
    "        str_t1 = 'T1 = %.3f\\n' %(s_trig)\n",
    "        str_p0 = 'P0 = %.3f\\n' %(p0)\n",
    "        str_s0 = 'S0 = %.3f\\n' %(s0)\n",
    "        window_list = [str_t0,str_t1,str_p0,str_s0] \n",
    "\n",
    "        #print('Filename:', tr_filename)\n",
    "        #print('Contents:\\n', window_list)\n",
    "\n",
    "        fqpname = dname + '/OBS/' + tr_filename\n",
    "        #print('fqn:',fqpname)\n",
    "        f = open(fqpname, 'w')\n",
    "        f.writelines(window_list)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. QC the triggers by overlaying on traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from obspy import Stream\n",
    "from obspy import Trace\n",
    "from gnam.specutils.read import spec_ascii_2_stream as a2st\n",
    "\n",
    "\n",
    "f1 = 2.0\n",
    "f2 = 6.0\n",
    "\n",
    "#get list of files for triggers\n",
    "#en = 1\n",
    "#del e_st\n",
    "for pair in dir_event_list[0:en]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    eid = eset['EKEY']\n",
    "    \n",
    "    obs_dir = dname + '/OBS/'\n",
    "    flist = []\n",
    "        \n",
    "    for file in os.listdir(obs_dir):\n",
    "        if file.endswith('.window'):\n",
    "            #print(os.path.join(obs_dir, file))\n",
    "            #flist.append(os.path.join(obs_dir, file))\n",
    "            flist.append(file)\n",
    "            \n",
    "    #sort by station name to make figure easier to read\n",
    "    flist.sort(key=lambda x:int(x.split('.')[1].split('G')[1]))\n",
    "    #jprint('flist:\\n',flist)\n",
    "    \n",
    "    #loop over list of files, overlay triggers on 3-component plot, save pdf\n",
    "    e_st = Stream()\n",
    "    wind_dict = {}\n",
    "    for f in flist:\n",
    "        #print(f)\n",
    "        head = f.split('.')\n",
    "        station = head[0] + '.' + head[1]\n",
    "        wind_fname = obs_dir + station + '.window'\n",
    "        df = pd.io.parsers.read_csv(wind_fname,sep='=',header=None, usecols=[0,1])\n",
    "        triggers = df[[1]].to_numpy().astype(np.float32).flatten()\n",
    "        wind_dict[head[1]] = triggers\n",
    "        \n",
    "        #read in 3-channels for each station\n",
    "        station_z = station + '.FXZ.semd'\n",
    "        station_y = station + '.FXY.semd'\n",
    "        station_x = station + '.FXX.semd'\n",
    "        for s in [station_z,station_y,station_x]:\n",
    "\n",
    "            #read ascii files and create obspy.Stream()\n",
    "            tr_fname = obs_dir + s\n",
    "            '''\n",
    "            print('tr_fname:',tr_fname)\n",
    "            df = pd.io.parsers.read_csv(tr_fname,sep='\\s+',header=None, usecols=[0,1])\n",
    "            data = df[[1]].to_numpy().astype(np.float32).flatten()\n",
    "            times = df[[0]].to_numpy().astype(np.float32).flatten()\n",
    "            fhdr = s.split('.')\n",
    "            stats = {'network': fhdr[0], 'station': fhdr[1], 'location': '', \n",
    "                    'channel': fhdr[2], 'npts': len(data), 'delta': times[1]-times[0]}\n",
    "            syntime = df[[0]].to_numpy().astype(np.float64).flatten()\n",
    "            stats['starttime'] = syntime[0]\n",
    "            st = Stream([Trace(data=data, header=stats)])\n",
    "            '''\n",
    "            st = a2st(tr_fname)\n",
    "            e_st += st\n",
    "            \n",
    "    #create pdf of tiggers overlayed on plots\n",
    "    #e_st.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "    plt_h = 2\n",
    "    plt_w = 14\n",
    "    ntrace = len(e_st)//3\n",
    "    plt_scale = ntrace\n",
    "    fig, ax = plt.subplots(plt_scale,figsize=(plt_w,plt_h*plt_scale))\n",
    "    fig.tight_layout()\n",
    "    for i in range(len(e_st[:3*ntrace:3])):        \n",
    "\n",
    "        ax[i].plot(e_st[i*3].times(),   e_st[i*3].data,   c='black',  zorder=2)\n",
    "        ax[i].plot(e_st[i*3+1].times(), e_st[i*3+1].data, c='green',  zorder=1)\n",
    "        ax[i].plot(e_st[i*3+2].times(), e_st[i*3+2].data, c='orange', zorder=1)\n",
    "\n",
    "        station_id = e_st[i*3].stats.station\n",
    "        overlay_title = 'Event: %d, Station: %s, Z(black), Y(green), X(orange)' %(eid,station_id)\n",
    "        \n",
    "        amin = np.min(e_st[i*3].data)\n",
    "        amin = np.min(np.array([amin,np.min(e_st[i*3+1].data)]))\n",
    "        amin = np.min(np.array([amin,np.min(e_st[i*3+2].data)]))\n",
    "        amax = np.max(e_st[i*3].data)\n",
    "        amax = np.max(np.array([amax,np.max(e_st[i*3+1].data)]))\n",
    "        amax = np.max(np.array([amax,np.max(e_st[i*3+2].data)]))\n",
    "        ax[i].vlines(x=wind_dict[station_id][0], ymin=amin, ymax=amax, colors='red')\n",
    "        ax[i].vlines(x=wind_dict[station_id][2], ymin=amin, ymax=amax, colors='red',linestyle='dashed')\n",
    "        ax[i].vlines(x=wind_dict[station_id][1], ymin=amin, ymax=amax, colors='blue')\n",
    "        ax[i].vlines(x=wind_dict[station_id][3], ymin=amin, ymax=amax, colors='blue',linestyle='dashed')\n",
    "\n",
    "        ax[i].set_title(overlay_title)\n",
    "        ax[i].set_xlabel(\"time (s)\")\n",
    "        ax[i].set_ylabel(\"displacement (m)\")\n",
    "\n",
    "        ax[i].grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "        ax[i].minorticks_on()\n",
    "        ax[i].grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "    fig.savefig(obs_dir + 'Event_' + str(eid) + '_Window_Picks.pdf', bbox_inches='tight')\n",
    "\n",
    "    del wind_dict\n",
    "    del e_st\n",
    "    print('Finished Event: %d'%(eid))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Test Filter and trim of observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnam.specutils.read import spec_ascii_2_stream as a2st\n",
    "from gnam.specutils.read import all_spec_ascii_that_match_2_stream as all2st\n",
    "from gnam.specutils.utils import trim_resample_stream\n",
    "from gnam.specutils.utils import bandpass_stream\n",
    "from obspy import Stream\n",
    "\n",
    "myen = 1\n",
    "#for pair in dir_event_list[0:en]:\n",
    "for pair in dir_event_list[0:myen]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    eid = eset['EKEY']\n",
    "    \n",
    "    obs_dir = dname + '/OBS/'\n",
    "    syn_dir = dname + '/SYN/'\n",
    "    \n",
    "    oe_st = all2st(obs_dir,'.semd')\n",
    "    se_st = all2st(syn_dir,'.semd')\n",
    "    print(len(se_st))\n",
    "    o_t0 = 0.0\n",
    "    s_t0 = 0.0\n",
    "    #o_tN = oe_st[0].times()[-1] #FIXME:\n",
    "    o_tN = 16.374 #FIXME:\n",
    "    s_tN = 16.374 #FIXME:\n",
    "    o_dt = oe_st[0].stats.delta\n",
    "    s_dt = se_st[0].stats.delta\n",
    "    filt_oe_st = bandpass_stream(oe_st,f1=2.0,f2=6.0,nc=4)\n",
    "    filt_se_st = bandpass_stream(se_st,f1=2.0,f2=6.0,nc=4)\n",
    "    trim_oe_st = trim_resample_stream(filt_oe_st,t0=o_t0,tN=o_tN,dt=o_dt)\n",
    "    trim_se_st = trim_resample_stream(filt_se_st,t0=s_t0,tN=s_tN,dt=s_dt)\n",
    "    \n",
    "    print('trim_oe_st:\\n',trim_oe_st[0:3])\n",
    "    print('trim_se_st:\\n',trim_se_st[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnam.specutils.read import spec_ascii_2_stream as a2st\n",
    "from gnam.specutils.read import all_spec_ascii_that_match_2_stream as all2st\n",
    "from gnam.specutils.utils import trim_resample_stream\n",
    "from gnam.specutils.utils import bandpass_stream\n",
    "from gnam.specutils.utils import conform_and_bandpass_streams_for_adjsrc as conform\n",
    "from gnam.specutils.utils import conform_and_bandpass_syn_2_obs as conf2obs\n",
    "from gnam.specutils.write import write_stream_2_spec_ascii as spec_wst2a\n",
    "from obspy import Stream\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "myen = 1\n",
    "'''\n",
    "#for pair in dir_event_list[0:en]:\n",
    "for pair in dir_event_list[0:myen]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    eid = eset['EKEY']\n",
    "    \n",
    "    obs_dir = dname + '/OBS/'\n",
    "    filt_obs_dir = dname + '/FILT_OBS'\n",
    "    syn_dir = dname + '/SYN/'\n",
    "    filt_syn_dir = dname + '/FILT_SYN'\n",
    "    \n",
    "    oe_st = all2st(obs_dir,'.semd')\n",
    "    se_st = all2st(syn_dir,'.semd')\n",
    "    \n",
    "    conform(oe_st,se_st,resamp=1000,tN=16.374,f1=2.0,f2=6.0)\n",
    "    spec_wst2a(oe_st,filt_obs_dir,is_zne=False)\n",
    "    spec_wst2a(se_st,filt_syn_dir,is_zne=False)\n",
    "    \n",
    "    print('oe_st:\\n',oe_st[0:3])\n",
    "    print('se_st:\\n',se_st[0:3])\n",
    "'''\n",
    "    \n",
    "for pair in dir_event_list[0:myen]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    eid = eset['EKEY']\n",
    "    \n",
    "    obs_dir = dname + '/OBS/'\n",
    "    filt_obs_dir = dname + '/FILT_OBS'\n",
    "    syn_dir = dname + '/SYN/'\n",
    "    filt_syn_dir = dname + '/FILT_SYN'\n",
    "    \n",
    "    oe_st = all2st(obs_dir,'.semd')\n",
    "    se_st = all2st(syn_dir,'.semd')\n",
    "    \n",
    "    conform(oe_st,se_st,resamp=1000,tN=16.374,f1=2.0,f2=6.0)\n",
    "    \n",
    "    trim_resample_stream(oe_st,t0=0.0,tN=16.0,resamp=500)\n",
    "    \n",
    "    conf2obs(oe_st,se_st,f1=2.0,f2=12.0)\n",
    "    spec_wst2a(se_st,filt_syn_dir,is_zne=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "#%cd /Users/mcmac/Documents/Work/Bench/Groningen/gnam/notebooks/Full_Workflow\n",
    "#%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
