{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SPECFEM3D Project\n",
    "1. Unpickle events and staions\n",
    "1. Read and map moment tensors to events\n",
    "1. Prep observed station data for writing to ascii files\n",
    "1. Write CMTSOLUTION, STATION, STATION_ADJOINT ascii files in appropriate dictories for each event\n",
    "1. Write adjoint source window parameter files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Unpickle events and stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gnam.events.gevents import gevents as gevents\n",
    "from gnam.events.gstations import gstations as gstations\n",
    "from gnam.events.munge.knmi import correct_station_depths as csd_f\n",
    "\n",
    "data_root_dir = '../../../data_notebooks'\n",
    "\n",
    "#Unpickle events\n",
    "print('Unpickling Events')\n",
    "f = open('../../../data_notebooks/pickled/events.pickle', 'rb')\n",
    "dill_events = pickle.load(f)\n",
    "f.close()\n",
    "    \n",
    "\n",
    "#Unpickle stations\n",
    "print('Unpickling Station Traces')\n",
    "f = open('../../../data_notebooks/pickled/straces.pickle', 'rb')\n",
    "dill_straces = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# This is kind of hokey, but it works for now.\n",
    "# Some of the stations depths do not follow the \n",
    "# 50, 100, 150, 200 meter depths -- possibly because\n",
    "# the boreholes are slanted. To correct for this,\n",
    "# a hard coded \"patch/update\" is applied. See the\n",
    "# code for details and update values.\n",
    "dill_straces.correct_stations(csd_f)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read and map moment tensors to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gnam.events.mtensors import mtensors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Get model bounding box needed for adjusting strike\n",
    "gf_bbox = dill_events.getBBox()\n",
    "\n",
    "#Read moment tensors\n",
    "#gf_mts = mtensors('../../../data_notebooks/data/event_moments.csv')\n",
    "gf_mts = mtensors('../../../data_notebooks/data/event_moments.csv',gf_bbox)\n",
    "    \n",
    "# get event catalog of the events withing the bounding box\n",
    "e_cat = dill_events.getIncCatalog()\n",
    "\n",
    "# This is a bit hokey, but it works. Here we update the\n",
    "# event time from the moment tensor CSV file with thouse\n",
    "# from the event catalog\n",
    "gf_mts.update_utcdatetime(e_cat)\n",
    "for imt in range(len(gf_mts)):\n",
    "    print(\"Moment-Tensor %d:\\n\" %(imt),gf_mts[imt])\n",
    "\n",
    "# Create a dictionary that maps moment tensors to events\n",
    "e2mt_dict = gf_mts.map_events_2_tensors(e_cat)\n",
    "e2mt_keys = e2mt_dict.keys()\n",
    "\n",
    "# Print a comparison of events to moment tensors\n",
    "for key in e2mt_keys:\n",
    "    print('UTC: event[%d][Date] = %s' %(key,e_cat[key].origins[0].time))\n",
    "    print('UTC:    MT[%d][Date] = %s' %(key,e2mt_dict[key]['Date']))\n",
    "    print('Mag: event[%d][Date] = %s' %(key,e_cat[key].magnitudes[0].mag))\n",
    "    print('Mag:    MT[%d][Date] = %s' %(key,e2mt_dict[key]['ML']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Prep observed station data for writing to ascii files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Stream\n",
    "\n",
    "#create streams and map eventid to stream\n",
    "e_stream_dict = {}\n",
    "ce_stream_dict = {}\n",
    "for ekey in e2mt_keys:\n",
    "    '''\n",
    "    e_st  = Stream()\n",
    "    e_st += dill_straces.getStreamZ(ekey,3) \n",
    "    e_st += dill_straces.getStreamZ(ekey,4) \n",
    "    e_st.resample(1000)\n",
    "    e_stream_dict[ekey] = e_st\n",
    "    '''\n",
    "    \n",
    "    #get boreholes 3 and 4 streams for the event\n",
    "    e1_st3 = dill_straces.getStream1(ekey,3)\n",
    "    e1_st4 = dill_straces.getStream1(ekey,4)\n",
    "    e2_st3 = dill_straces.getStream2(ekey,3)\n",
    "    e2_st4 = dill_straces.getStream2(ekey,4)\n",
    "    ez_st3 = dill_straces.getStreamZ(ekey,3)\n",
    "    ez_st4 = dill_straces.getStreamZ(ekey,4)\n",
    "\n",
    "    #combine component streams\n",
    "    e_st3 = e1_st3 + e2_st3 + ez_st3\n",
    "    e_st4 = e1_st4 + e2_st4 + ez_st4\n",
    "\n",
    "    #reorder streams so that each station component is contiguous\n",
    "    te_st3 = Stream()\n",
    "    te_st4 = Stream()\n",
    "\n",
    "    ns = len(ez_st3)\n",
    "    for i in range(ns):\n",
    "        te_st3 += e_st3[i+2*ns]\n",
    "        te_st3 += e_st3[i+ns]\n",
    "        te_st3 += e_st3[i]\n",
    "\n",
    "        te_st4 += e_st4[i+2*ns]\n",
    "        te_st4 += e_st4[i+ns]\n",
    "        te_st4 += e_st4[i]\n",
    "    \n",
    "    e_st3 = te_st3\n",
    "    e_st4 = te_st4\n",
    "    \n",
    "    #rotate the streams to ZNE components (obspy and the FDSN info is used)\n",
    "    inv3 = dill_straces.get_inventory(3)\n",
    "    inv4 = dill_straces.get_inventory(4)\n",
    "    e_st3.rotate(method=\"->ZNE\", inventory=inv3)\n",
    "    e_st4.rotate(method=\"->ZNE\", inventory=inv4)\n",
    "\n",
    "    #resample and map event to stream\n",
    "    e_st = e_st3 + e_st4\n",
    "    ce_st = e_st.copy() #keep a pre-resampled set for P-arrival picking (less memory)\n",
    "    #e_st.resample(1000) #better to resample while iterating. \n",
    "    e_stream_dict[ekey] = e_st\n",
    "    ce_stream_dict[ekey] = ce_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  Setup and test DATA directories and specfem3d file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiments = []\n",
    "for ekey in e2mt_keys:\n",
    "    bkeys = dill_straces.getBoreholeKeys()\n",
    "    bh_stat_list = []\n",
    "    for bkey in bkeys:\n",
    "        bh_stat_list.append(dill_straces.getIncludedStations(ekey,bkey))\n",
    "    bh_stat_tup = tuple(bh_stat_list)   \n",
    "    exp_set = {'EKEY':ekey,'EVENT':e_cat[ekey],'TENSOR':e2mt_dict[ekey],'STATIONS':bh_stat_tup}\n",
    "    experiments.append(exp_set)\n",
    "\n",
    "dir_set_list = []\n",
    "min_eid = experiments[0]['EKEY']\n",
    "for eset in experiments:\n",
    "    eid = eset['EKEY']\n",
    "    if eid < min_eid:\n",
    "        min_eid = eid\n",
    "        \n",
    "dir_event_list = []\n",
    "for eset in experiments:\n",
    "    rdir = eset['EKEY'] - min_eid + 1\n",
    "    rdir = 'run%s' %(str(rdir).zfill(4))\n",
    "    dname = data_root_dir + '/SPECFEM3D/project/%s' %(rdir)\n",
    "    dir_event_list.append((eset,dname))\n",
    "    print('Experiment-%d:\\n'%(eset['EKEY']), dname)\n",
    "    print()\n",
    "dir_event_list = dir_event_list[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  Create directories and write CMTSOLUTION, STATION, STATION_ADJOINT, and trace ascii files in separate dictories for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = 3 #last event (really it's: en-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gnam.specutils.write import write_cmtsolution as spec_wcmt\n",
    "from gnam.specutils.write import write_stations as spec_ws\n",
    "from gnam.specutils.write import write_stream_2_spec_ascii as spec_wst2a\n",
    "import os\n",
    "\n",
    "nproc = 16\n",
    "\n",
    "# define the access rights\n",
    "access_rights = 0o755\n",
    "\n",
    "#loop over dir-set pairs\n",
    "for pair in dir_event_list[0:en]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    new_dir = dname + '/DATA'\n",
    "    print('Experiment-%d:\\n'%(eset['EKEY']), dname)\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        bkeys = dill_straces.getBoreholeKeys()\n",
    "        lxy = dill_events.getLocalEventCoord(eset['EKEY'])\n",
    "        spec_wcmt(new_dir + '/CMTSOLUTION',eset['TENSOR'],lxy[0],lxy[1])\n",
    "        spec_ws(new_dir + '/STATIONS',dill_straces,eset['EKEY'],bkeys)\n",
    "        spec_ws(new_dir + '/STATIONS_ADJOINT',dill_straces,eset['EKEY'],bkeys)\n",
    "        \n",
    "        #add links to bin and utils\n",
    "        src = '/quanta1/home/tcullison/DevGPU_specfem3d/bin'\n",
    "        dst = dname + '/bin'\n",
    "        os.symlink(src, dst)\n",
    "        src = '/quanta1/home/tcullison/DevGPU_specfem3d/utils'\n",
    "        dst = dname + '/utils'\n",
    "        os.symlink(src, dst)\n",
    "        \n",
    "    #add OUTPUT_FILES/DATABASES_MPI dirs\n",
    "    new_dir  = dname + '/OUTPUT_FILES/DATABASES_MPI'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        if eset['EKEY'] != min_eid:\n",
    "            #for k in ['Database','vp.bin','vs.bin','rho.bin']:\n",
    "            for k in ['Database','external_mesh.bin']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    mesh_fname = 'proc%s_%s' %(iproc,k)\n",
    "                    src = '../../../run0001/OUTPUT_FILES/DATABASES_MPI' + mesh_fname\n",
    "                    dst = new_dir + '/' + mesh_fname\n",
    "                    os.symlink(src, dst)\n",
    "            mesh_fname = 'surface_from_mesher.h'\n",
    "            src = '../../../run0001/OUTPUT_FILES/' + mesh_fname\n",
    "            dst = dname + '/OUTPUT_FILES/' + mesh_fname\n",
    "            os.symlink(src, dst)\n",
    "            mesh_fname = 'values_from_mesher.h'\n",
    "            src = '../../run0001/OUTPUT_FILES/' + mesh_fname\n",
    "            dst = dname + '/OUTPUT_FILES/' + mesh_fname\n",
    "            os.symlink(src, dst)\n",
    "    \n",
    "    #add OBS dir\n",
    "    new_dir  = dname + '/OBS'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "    else:\n",
    "        eid = eset['EKEY']\n",
    "        e_st = e_stream_dict[eid]\n",
    "        '''\n",
    "        for tr in e_st:\n",
    "            spec_pair_list = [] #time,amplitude pairs\n",
    "\n",
    "            #Example of filename: 'NL.G094.FXX.semd'\n",
    "            tr_filename = 'NL.' + tr.stats.station + '.FXZ.semd'\n",
    "            print('filename:',tr_filename)\n",
    "\n",
    "            for it in range(tr.count()):\n",
    "                spec_pair_list.append('%E   %E\\n' %(tr.times()[it],tr.data[it]))\n",
    "\n",
    "            fqpname = new_dir + '/' + tr_filename\n",
    "            f = open(fqpname, 'w')\n",
    "            f.writelines(spec_pair_list)\n",
    "            f.close()\n",
    "            #Example of filename: 'NL.G094.FXX.semd'\n",
    "            tr_spec_chan = '.BOO.'\n",
    "            comp_char = tr.stats.channel[2] \n",
    "            if comp_char == 'Z':\n",
    "                tr_spec_chan = '.FXZ.'\n",
    "            elif comp_char == 'E':\n",
    "                tr_spec_chan = '.FXX.'\n",
    "            elif comp_char == 'N':\n",
    "                tr_spec_chan = '.FXY.'\n",
    "            else:\n",
    "                print('Uh-oh! Spaghetti Os!')\n",
    "\n",
    "            tr_filename = 'NL.' + tr.stats.station + tr_spec_chan + 'semd'\n",
    "\n",
    "            for it in range(tr.count()):\n",
    "                spec_pair_list.append('%E   %E\\n' %(tr.times()[it],tr.data[it]))\n",
    "\n",
    "            fqpname = new_dir + '/' + tr_filename\n",
    "            f = open(fqpname, 'w')\n",
    "            f.writelines(spec_pair_list)\n",
    "            f.close()\n",
    "        '''\n",
    "        #write specfem3d ascii files \n",
    "        spec_wst2a(e_st,new_dir,is_zne=True) \n",
    "        \n",
    "        \n",
    "    #add FILT_OBS dir\n",
    "    new_dir  = dname + '/FILT_OBS'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add SYN dir\n",
    "    new_dir  = dname + '/SYN'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add FILT_SYN dir\n",
    "    new_dir  = dname + '/FILT_SYN'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #add SEM dir\n",
    "    new_dir  = dname + '/SEM'\n",
    "    try:\n",
    "        os.makedirs(new_dir, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #if run0001 dir (this is were the model setup and update happens)\n",
    "    if eset['EKEY'] == min_eid:\n",
    "        \n",
    "        #add INPUT_KERNELS dir\n",
    "        new_dir  = dname + '/INPUT_KERNELS'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add INPUT_MODEL dir\n",
    "        new_dir  = dname + '/INPUT_MODEL'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add OUTPUT_MODEL dir\n",
    "        new_dir  = dname + '/OUTPUT_MODEL'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add OUTPUT_SUM dir\n",
    "        new_dir  = dname + '/OUTPUT_SUM'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        \n",
    "        #add SMOOTH dir\n",
    "        new_dir  = dname + '/SMOOTH'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for k in ['alpha','beta','rho','hess']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    kernel_fname = 'proc%s_%s_kernel' %(iproc,k)\n",
    "                    src = './' + kernel_fname + '_smooth.bin'\n",
    "                    dst = new_dir + '/' + kernel_fname + '.bin'\n",
    "                    os.symlink(src, dst)\n",
    "        \n",
    "        #add INPUT_GRADIENT dir\n",
    "        new_dir  = dname + '/INPUT_GRADIENT'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for k in ['alpha','beta','rho','hess']:\n",
    "                for i in range(nproc):\n",
    "                    iproc = str(i).zfill(6)\n",
    "                    kernel_fname = 'proc%s_%s_kernel_smooth' %(iproc,k)\n",
    "                    src = '../SMOOTH/' + kernel_fname + '.bin'\n",
    "                    dst = new_dir + '/' + kernel_fname + '.bin'\n",
    "                    os.symlink(src, dst)\n",
    "            \n",
    "        #add topo dir\n",
    "        new_dir  = dname + '/topo'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n",
    "        else:\n",
    "            for i in range(nproc):\n",
    "                iproc = str(i).zfill(6)\n",
    "                ext_mesh_fname = 'proc%s_external_mesh.bin' %(iproc)\n",
    "                src = '../OUTPUT_FILES/DATABASES_MPI/' + ext_mesh_fname\n",
    "                dst = new_dir + '/' + ext_mesh_fname\n",
    "                os.symlink(src, dst)\n",
    "                \n",
    "        #add COMBINE dir (empty)\n",
    "        new_dir  = dname + '/COMBINE'\n",
    "        try:\n",
    "            os.makedirs(new_dir, access_rights)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Write adjoint source window parameter files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import Stream\n",
    "from obspy import Trace\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "\n",
    "#loop over dir-set pairs\n",
    "for pair in dir_event_list[0:en]:\n",
    "    eset  = pair[0]\n",
    "    dname = pair[1]\n",
    "    eid = eset['EKEY']\n",
    "    trig_dict = event_trigger_dict[eid]\n",
    "    \n",
    "    t1 = 2\n",
    "    for key in trig_dict:\n",
    "\n",
    "        tr_filename = 'NL.' + key + '.window'\n",
    "\n",
    "        p_trig = trig_dict[key][0]\n",
    "        p0     = trig_dict[key][1]\n",
    "        s0     = trig_dict[key][2]\n",
    "        s_trig = trig_dict[key][3]\n",
    "        str_t0 = 'T0 = %.3f\\n' %(p_trig)\n",
    "        str_t1 = 'T1 = %.3f\\n' %(s_trig)\n",
    "        str_p0 = 'P0 = %.3f\\n' %(p0)\n",
    "        str_s0 = 'S0 = %.3f\\n' %(s0)\n",
    "        window_list = [str_t0,str_t1,str_p0,str_s0] \n",
    "\n",
    "        #print('Filename:', tr_filename)\n",
    "        #print('Contents:\\n', window_list)\n",
    "\n",
    "        fqpname = dname + '/OBS/' + tr_filename\n",
    "        #print('fqn:',fqpname)\n",
    "        f = open(fqpname, 'w')\n",
    "        f.writelines(window_list)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
