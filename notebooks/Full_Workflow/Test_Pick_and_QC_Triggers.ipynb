{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SPECFEM3D Project\n",
    "1. Unpickle events and staions\n",
    "1. Read and map moment tensors to events\n",
    "1. Prep observed station data for writing to ascii files\n",
    "1. Setup and test DATA directories and specfem3d file names\n",
    "1. Create directories and write CMTSOLUTION, STATION, STATION_ADJOINT, and trace ascii files in separate dictories for each event\n",
    "1. Test P-arrival pick on one trace\n",
    "1. Plot p-arrivals for all traces of a chosen event\n",
    "1. Create p-arriavls (trigger) dictionary for all events\n",
    "1. Write adjoint source window parameter files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Unpickle events and stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gnam.events.gevents import gevents as gevents\n",
    "from gnam.events.gstations import gstations as gstations\n",
    "from gnam.events.munge.knmi import correct_station_depths as csd_f\n",
    "\n",
    "data_root_dir = '../../../data_notebooks'\n",
    "\n",
    "#Unpickle events\n",
    "print('Unpickling Events')\n",
    "f = open('../../../data_notebooks/pickled/events.pickle', 'rb')\n",
    "dill_events = pickle.load(f)\n",
    "f.close()\n",
    "    \n",
    "\n",
    "#Unpickle stations\n",
    "print('Unpickling Station Traces')\n",
    "f = open('../../../data_notebooks/pickled/straces.pickle', 'rb')\n",
    "dill_straces = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# This is kind of hokey, but it works for now.\n",
    "# Some of the stations depths do not follow the \n",
    "# 50, 100, 150, 200 meter depths -- possibly because\n",
    "# the boreholes are slanted. To correct for this,\n",
    "# a hard coded \"patch/update\" is applied. See the\n",
    "# code for details and update values.\n",
    "dill_straces.correct_stations(csd_f)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read and map moment tensors to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gnam.events.mtensors import mtensors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Get model bounding box needed for adjusting strike\n",
    "gf_bbox = dill_events.getBBox()\n",
    "\n",
    "#Read moment tensors\n",
    "gf_mts = mtensors('../../../data_notebooks/data/event_moments.csv',gf_bbox)\n",
    "    \n",
    "# get event catalog of the events withing the bounding box\n",
    "e_cat = dill_events.getIncCatalog()\n",
    "\n",
    "# This is a bit hokey, but it works. Here we update the\n",
    "# event time from the moment tensor CSV file with thouse\n",
    "# from the event catalog\n",
    "gf_mts.update_utcdatetime(e_cat)\n",
    "\n",
    "# Create a dictionary that maps moment tensors to events\n",
    "e2mt_dict = gf_mts.map_events_2_tensors(e_cat)\n",
    "e2mt_keys = e2mt_dict.keys()\n",
    "\n",
    "# Print a comparison of events to moment tensors\n",
    "for key in e2mt_keys:\n",
    "    print('UTC: event[%d][Date] = %s' %(key,e_cat[key].origins[0].time))\n",
    "    print('UTC:    MT[%d][Date] = %s' %(key,e2mt_dict[key]['Date']))\n",
    "    print('Mag: event[%d][Date] = %s' %(key,e_cat[key].magnitudes[0].mag))\n",
    "    print('Mag:    MT[%d][Date] = %s' %(key,e2mt_dict[key]['ML']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create Streams and dictionars of all event station catalogs that are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Stream\n",
    "\n",
    "#create streams and map eventid to stream\n",
    "e_stream_dict = {}\n",
    "ce_stream_dict = {}\n",
    "for ekey in e2mt_keys:\n",
    "    '''\n",
    "    e_st  = Stream()\n",
    "    e_st += dill_straces.getStreamZ(ekey,3) \n",
    "    e_st += dill_straces.getStreamZ(ekey,4) \n",
    "    e_st.resample(1000)\n",
    "    e_stream_dict[ekey] = e_st\n",
    "    '''\n",
    "    \n",
    "    #get boreholes 3 and 4 streams for the event\n",
    "    e1_st3 = dill_straces.getStream1(ekey,3).copy()\n",
    "    e1_st4 = dill_straces.getStream1(ekey,4).copy()\n",
    "    e2_st3 = dill_straces.getStream2(ekey,3).copy()\n",
    "    e2_st4 = dill_straces.getStream2(ekey,4).copy()\n",
    "    ez_st3 = dill_straces.getStreamZ(ekey,3).copy()\n",
    "    ez_st4 = dill_straces.getStreamZ(ekey,4).copy()\n",
    "\n",
    "    #combine component streams\n",
    "    e_st3 = e1_st3 + e2_st3 + ez_st3\n",
    "    e_st4 = e1_st4 + e2_st4 + ez_st4\n",
    "\n",
    "    #reorder streams so that each station component is contiguous\n",
    "    te_st3 = Stream()\n",
    "    te_st4 = Stream()\n",
    "\n",
    "    ns = len(ez_st3)\n",
    "    for i in range(ns):\n",
    "        te_st3 += e_st3[i+2*ns]\n",
    "        te_st3 += e_st3[i+ns]\n",
    "        te_st3 += e_st3[i]\n",
    "\n",
    "        te_st4 += e_st4[i+2*ns]\n",
    "        te_st4 += e_st4[i+ns]\n",
    "        te_st4 += e_st4[i]\n",
    "    \n",
    "    e_st3 = te_st3\n",
    "    e_st4 = te_st4\n",
    "    \n",
    "    #rotate the streams to ZNE components (obspy and the FDSN info is used)\n",
    "    inv3 = dill_straces.get_inventory(3)\n",
    "    inv4 = dill_straces.get_inventory(4)\n",
    "    \n",
    "    trZ = e_st3[0]\n",
    "    trZ_name = trZ.stats.network + '.' + trZ.stats.station + '..' + trZ.stats.channel\n",
    "    #trZ_orient = {}\n",
    "    trZ_orient = inv3.get_orientation(trZ_name)\n",
    "    print('%s orientaion' %(trZ_name), trZ_orient)\n",
    "    tr1 = e_st3[1]\n",
    "    tr1_name = tr1.stats.network + '.' + tr1.stats.station + '..' + tr1.stats.channel\n",
    "    #tr1_orient = {}\n",
    "    tr1_orient = inv3.get_orientation(tr1_name)\n",
    "    print('%s orientaion' %(tr1_name), tr1_orient)\n",
    "    tr2 = e_st3[2]\n",
    "    tr2_name = tr2.stats.network + '.' + tr2.stats.station + '..' + tr2.stats.channel\n",
    "    #tr2_orient = {}\n",
    "    tr2_orient = inv3.get_orientation(tr2_name)\n",
    "    print('%s orientaion' %(tr2_name), tr2_orient)\n",
    "    \n",
    "    e_st3.rotate(method=\"->ZNE\", inventory=inv3)\n",
    "    e_st4.rotate(method=\"->ZNE\", inventory=inv4)\n",
    "\n",
    "    #resample and map event to stream\n",
    "    e_st = e_st3 + e_st4\n",
    "    ce_st = e_st.copy() #keep a pre-resampled set for P-arrival picking (less memory)\n",
    "    #e_st.resample(1000) #better to resample while iterating. \n",
    "    e_stream_dict[ekey] = e_st\n",
    "    ce_stream_dict[ekey] = ce_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e_stream_dict[3].sort()[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test P-arrival pick on one trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from obspy.core import read\n",
    "from obspy.signal.trigger import ar_pick\n",
    "\n",
    "\n",
    "czne_st = ce_st.copy()\n",
    "\n",
    "df = czne_st[0].stats.sampling_rate\n",
    "f1 = 3.0\n",
    "f2 = 5.0\n",
    "lta_p = 1.0\n",
    "sta_p = 0.1\n",
    "lta_s = 4.0\n",
    "sta_s = 1.0\n",
    "m_p = 2\n",
    "m_s = 8\n",
    "l_p = 0.1\n",
    "l_s = 0.2\n",
    "\n",
    "p_sfudge = 0.75\n",
    "s_efudge = 0.75\n",
    "\n",
    "czne_st[0:3].filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "\n",
    "p_pick, s_pick = ar_pick(czne_st[0].data, czne_st[1].data, czne_st[2].data, df,\n",
    "                         f1, f2, lta_p, sta_p, lta_s, sta_s, m_p, m_s, l_p, l_s)\n",
    "\n",
    "#print(p_pick)\n",
    "#print(s_pick)\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(14,5))\n",
    "#print('czne_st[0]:\\n',vars(czne_st[0]))\n",
    "z_data = czne_st[0].data\n",
    "n_data = czne_st[1].data\n",
    "e_data = czne_st[2].data\n",
    "dt     = czne_st[0].stats.delta\n",
    "nt     = czne_st[0].count()\n",
    "t      = czne_st[0].times()\n",
    "#print('dt:',dt)\n",
    "#print('nt:',nt)\n",
    "#print('df:',df)\n",
    "ax.plot(t, z_data,c='black')\n",
    "ax.plot(t, n_data,c='green')\n",
    "ax.plot(t, e_data,c='orange')\n",
    "amin_z = np.min(z_data)\n",
    "amax_z = np.max(z_data)\n",
    "amin_n = np.min(n_data)\n",
    "amax_n = np.max(n_data)\n",
    "amin_e = np.min(e_data)\n",
    "amax_e = np.max(e_data)\n",
    "amin = np.min([amin_z,amin_n,amin_e])*2\n",
    "amax = np.max([amax_z,amax_n,amax_e])*2\n",
    "#print('amax:',amax)\n",
    "#print('amin:',amin)\n",
    "ax.vlines(x=p_pick, ymin=amin, ymax=amax, colors='red',linestyle='dashed')\n",
    "ax.vlines(x=p_pick-p_sfudge, ymin=amin, ymax=amax, colors='red')\n",
    "ax.vlines(x=s_pick, ymin=amin, ymax=amax, colors='blue',linestyle='dashed')\n",
    "ax.vlines(x=s_pick+s_efudge, ymin=amin, ymax=amax, colors='blue')\n",
    "\n",
    "plt.grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "plt.minorticks_on()\n",
    "plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Plot p-arrivals for all traces of a chosen event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose event between min and max ekey (some events don't have inverted moment tensors yet)\n",
    "import numpy.random as rand\n",
    "#rand.seed(2)\n",
    "cekeys = ce_stream_dict.keys()\n",
    "min_cekey = min(cekeys)\n",
    "max_cekey = max(cekeys)\n",
    "print('min key:',min_cekey)\n",
    "print('max key:',max_cekey)\n",
    "rand_cekey = rand.randint(min_cekey, max_cekey)\n",
    "#rand_cekey = min_cekey\n",
    "rand_cekey = 3\n",
    "print(rand_cekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triggers(p_0,s_0,p_trig_pad,s_trig_pad):\n",
    "    if s_0 < p_0:\n",
    "        s_0 = 2.1*p_0\n",
    "    if (s_0 - p_0) < 2.0:\n",
    "        s_0 = p_0 + 2.0\n",
    "        \n",
    "    #if the padded p-pick is less then zero, set to zero\n",
    "    p_trig = p_0 - p_trig_pad\n",
    "    if p_trig < 0.0:\n",
    "        p_trig = 0.0\n",
    "    #if the padded s-pick is greater than the last time sample, set to the last sample\n",
    "    s_trig = s_0 + s_trig_pad\n",
    "    if t[-1] <= s_trig:\n",
    "        s_trig = t[-1]\n",
    "        \n",
    "    return (p_trig,p_0,s_0,s_trig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the picks on the trances for the chosen event.\n",
    "import obspy\n",
    "from obspy import Stream\n",
    "from obspy import Trace\n",
    "from obspy import UTCDateTime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy \n",
    "from obspy.signal.trigger import recursive_sta_lta\n",
    "from obspy.signal.trigger import plot_trigger\n",
    "\n",
    "dc_real = copy.deepcopy(ce_stream_dict[rand_cekey])\n",
    "df = ce_st[0].stats.sampling_rate\n",
    "f1 = 4.0\n",
    "f2 = 16.0\n",
    "lta_p = 1.5\n",
    "sta_p = 0.5\n",
    "lta_s = 2\n",
    "sta_s = 0.5\n",
    "m_p = 8\n",
    "m_s = 8\n",
    "l_p = 0.5\n",
    "l_s = 0.5\n",
    "\n",
    "p_trig_pad = 0.75\n",
    "s_trig_pad = 0.75\n",
    "\n",
    "dc_real.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "\n",
    "plt_h = 2\n",
    "plt_w = 14\n",
    "ntrace = len(dc_real)//3\n",
    "plt_scale = int(1*len(dc_real[:3*ntrace:3]))\n",
    "fig, ax = plt.subplots(plt_scale,figsize=(plt_w,plt_h*plt_scale))\n",
    "fig.tight_layout()\n",
    "zshft = int(0)\n",
    "nshft = int(1)\n",
    "eshft = int(2)\n",
    "shft = zshft\n",
    "triggers = np.zeros((ntrace,4))\n",
    "trig_dict = {}\n",
    "for i in range(len(dc_real[:3*ntrace:3])):\n",
    "    \n",
    "    #dc_real[shft+i*3].filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "    \n",
    "    #real_data = dc_real[shft+i*3].data\n",
    "    \n",
    "    dt     = dc_real[i*3].stats.delta\n",
    "    nt     = dc_real[i*3].count()\n",
    "    t      = dc_real[i*3].times()\n",
    "    \n",
    "    p_0, s_0 = ar_pick(dc_real[i*3].data, dc_real[i*3+1].data, dc_real[i*3+2].data, df, \n",
    "                       f1, f2, lta_p, sta_p, lta_s, sta_s, m_p, m_s, l_p, l_s)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    if s_0 < p_0:\n",
    "        s_0 = 2.1*p_0\n",
    "    if (s_0 - p_0) < 2.0:\n",
    "        s_0 = p_0 + 2.0\n",
    "    assert 2.0 <= (s_0 - p_0)\n",
    "        \n",
    "    #if the padded p-pick is less then zero, set to zero\n",
    "    p_trig = p_0 - p_trig_pad\n",
    "    if p_trig < 0.0:\n",
    "        p_trig = 0.0\n",
    "    #if the padded s-pick is greater than the last time sample, set to the last sample\n",
    "    s_trig = s_0 + s_trig_pad\n",
    "    if t[-1] <= s_trig:\n",
    "        s_trig = t[-1]\n",
    "    '''\n",
    "    p_trig, p_0, s_0, s_trig = get_triggers(p_0,s_0,p_trig_pad,s_trig_pad)\n",
    "        \n",
    "    triggers[i,0] = p_trig\n",
    "    triggers[i,1] = p_0\n",
    "    triggers[i,2] = s_0\n",
    "    triggers[i,3] = s_trig\n",
    "    trig_dict[dc_real[shft+i*3].stats.station] = np.array(triggers[i,:])\n",
    "    print('event %d: trig %s:' %(rand_cekey,dc_real[shft+i*3].stats.station), np.array(triggers[i,:]))\n",
    "    \n",
    "    ax[i].plot(t, dc_real[i*3].data,c='black',zorder=2)\n",
    "    ax[i].plot(t, dc_real[i*3+1],c='green',zorder=1)\n",
    "    ax[i].plot(t, dc_real[i*3+2],c='orange',zorder=0)\n",
    "    \n",
    "    amin = np.min(dc_real[i*3].data)\n",
    "    amin = np.min(np.array([amin,np.min(dc_real[i*3+1].data)]))\n",
    "    amin = np.min(np.array([amin,np.min(dc_real[i*3+2].data)]))\n",
    "    amax = np.max(dc_real[i*3].data)\n",
    "    amax = np.max(np.array([amax,np.max(dc_real[i*3+1].data)]))\n",
    "    amax = np.max(np.array([amax,np.max(dc_real[i*3+2].data)]))\n",
    "    ax[i].vlines(x=p_0, ymin=amin, ymax=amax, colors='red',linestyle='dashed')\n",
    "    ax[i].vlines(x=p_trig, ymin=amin, ymax=amax, colors='red')\n",
    "    ax[i].vlines(x=s_0, ymin=amin, ymax=amax, colors='blue',linestyle='dashed')\n",
    "    ax[i].vlines(x=s_trig, ymin=amin, ymax=amax, colors='blue')\n",
    "    \n",
    "    rstation = dc_real[i*3].stats.station\n",
    "    rstation += '.' + dc_real[shft+i*3].stats.channel\n",
    "    \n",
    "    overlay_title = 'Station:' + str(rstation)\n",
    "    ax[i].set_title(overlay_title)\n",
    "    \n",
    "    ax[i].grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "    ax[i].minorticks_on()\n",
    "    ax[i].grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create p-arriavls (trigger) dictionary for all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = [3,4,5]\n",
    "event_trigger_dict = {}\n",
    "for eid in event_list:\n",
    "\n",
    "    #make copy so that it can be filtered to a good band for picking\n",
    "    dc_real = ce_stream_dict[eid].copy()\n",
    "    \n",
    "    dc_real.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "\n",
    "    ntrace = len(dc_real)//3\n",
    "    triggers = np.zeros((ntrace,4))\n",
    "    trig_dict = {}\n",
    "    for i in range(len(dc_real[:3*ntrace:3])):\n",
    "\n",
    "        t      = dc_real[i*3].times()\n",
    "\n",
    "        p_0, s_0 = ar_pick(dc_real[i*3].data, dc_real[i*3+1].data, dc_real[i*3+2].data, df, \n",
    "                           f1, f2, lta_p, sta_p, lta_s, sta_s, m_p, m_s, l_p, l_s)\n",
    "\n",
    "\n",
    "        p_trig, p_0, s_0, s_trig = get_triggers(p_0,s_0,p_trig_pad,s_trig_pad)\n",
    "        \n",
    "        triggers[i,0] = p_trig\n",
    "        triggers[i,1] = p_0\n",
    "        triggers[i,2] = s_0\n",
    "        triggers[i,3] = s_trig\n",
    "        trig_dict[dc_real[i*3].stats.station] = np.array(triggers[i,:])\n",
    "        print('event %d: trig %s:' %(eid,dc_real[shft+i*3].stats.station), np.array(triggers[i,:]))\n",
    "        \n",
    "    #end sloop over station (and component) traces\n",
    "        \n",
    "    event_trigger_dict[eid] = trig_dict\n",
    "    \n",
    "#end loop over events\n",
    "print(event_trigger_dict[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read SPECFEM syn data and store into Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import Stream\n",
    "from obspy import Trace\n",
    "from obspy import UTCDateTime\n",
    "import fnmatch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dpath = '../../../data_notebooks/data/syn/'\n",
    "subdir = 'SYN/'\n",
    "\n",
    "emax = 5\n",
    "eshift = 2 # run dirs start at 0001, but not all obs events have a Moment Tensor\n",
    "esyn_dict = {}\n",
    "# read all filenames for each event\n",
    "for ekey in e2mt_keys:\n",
    "    esyn_key = ekey - eshift\n",
    "    if emax < ekey or esyn_key <= 0:\n",
    "        continue\n",
    "    rdir = 'run%s/' %(str(esyn_key).zfill(4))\n",
    "    fqdp = dpath + rdir + subdir\n",
    "    print('fqdp:',fqdp)\n",
    "    \n",
    "    obs_event = dill_events.getIncCatalog()[ekey]\n",
    "    etime = obs_event.origins[0].time\n",
    "    print('etime:',etime)\n",
    "    \n",
    "    syn_st = Stream()\n",
    "    for file in os.listdir(fqdp):\n",
    "        if fnmatch.fnmatch(file, '*semd'):\n",
    "            fqn = fqdp + file\n",
    "            df = pd.io.parsers.read_csv(fqn,sep=\"\\s+\",header=None, usecols=[0,1])\n",
    "            data = df[[1]].to_numpy().astype(np.float32).flatten()\n",
    "            fhdr = file.split('.')\n",
    "            # Fill header attributes\n",
    "            stats = {'network': fhdr[0], 'station': fhdr[1], 'location': '',\n",
    "                     'channel': fhdr[2], 'npts': len(data), 'delta': 0.001}\n",
    "            \n",
    "            syntime = df[[0]].to_numpy().astype(np.float64).flatten()\n",
    "            print('starttime:        ',etime)\n",
    "            stats['starttime'] = etime + syntime[0]\n",
    "            print('starttime shifted:',stats['starttime'])\n",
    "            st = Stream([Trace(data=data, header=stats)])\n",
    "            print('Stream Before Resample:\\n', st)\n",
    "            print('endtime shifted:  ',st[0].stats.endtime)\n",
    "            print('sampling:',st[0].stats.sampling_rate)\n",
    "            st[0].resample(200)\n",
    "            print('resampling:',st[0].stats.sampling_rate)\n",
    "            print('Stream After Resample:\\n', st)\n",
    "            print('delta:  ',st[0].stats.delta)\n",
    "            print('resamp starttime:  ',st[0].stats.starttime)\n",
    "            print('resamp endtime:    ',st[0].stats.endtime)\n",
    "            print('resamp len(data)   ',len(st[0].data))\n",
    "            endtime = st[0].stats.endtime\n",
    "            st[0] = st[0].slice(etime,endtime)\n",
    "            print('sliced starttime:  ',st[0].stats.starttime)\n",
    "            print('sliced endtime:    ',st[0].stats.endtime)\n",
    "            print('sliced len(data)   ',len(st[0].data))\n",
    "            syn_st += st\n",
    "            \n",
    "    esyn_dict[ekey] = syn_st.sort()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(esyn_dict[3][0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register Syn and Obs Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First change station names for ease of comparison\n",
    "rot_ce_stream_dict = {}\n",
    "for key in ce_stream_dict:\n",
    "    ce_st = ce_stream_dict[key].copy()\n",
    "    for itr in range(len(ce_st)//3):\n",
    "        dataE = None\n",
    "        dataN = None\n",
    "        itrE = None\n",
    "        itrN = None\n",
    "        #print('iitr:',3*itr)\n",
    "        for i in range(3):\n",
    "            iitr = 3*itr + i\n",
    "            tr = ce_st[iitr]\n",
    "            comp_char = tr.stats.channel[2] \n",
    "            if comp_char == 'Z':\n",
    "                continue\n",
    "            #print('Before - station.channel:', tr.stats.station + '.' + tr.stats.channel)\n",
    "            if comp_char == 'E':\n",
    "                tr.stats.channel = 'HHX'\n",
    "                itrE = iitr\n",
    "                dataE = tr.data.copy()\n",
    "            elif comp_char == 'N':\n",
    "                tr.stats.channel = 'HHY'\n",
    "                itrN = iitr\n",
    "                dataN = tr.data.copy()\n",
    "            #print('After  - station.channel:', tr.stats.station + '.' + tr.stats.channel)\n",
    "            #print()\n",
    "        \n",
    "        dataNp = dataN*np.cos(-2*np.pi/3) + dataE*np.sin(-2*np.pi/3)\n",
    "        dataEp = dataE*np.cos(-np.pi/6) + dataN*np.sin(-np.pi/6)\n",
    "        #print('itrN:',itrN)\n",
    "        #print('itrE:',itrE)\n",
    "        ce_st[itrN].data[:] = dataNp[:]\n",
    "        ce_st[itrE].data[:] = dataEp[:]\n",
    "        \n",
    "    rot_ce_stream_dict[key] = ce_st\n",
    "\n",
    "#Now register the data\n",
    "reg_obs_st_dict = {}\n",
    "reg_syn_st_dict = {}\n",
    "for key in esyn_dict:\n",
    "    print('KEY:',key)\n",
    "    obs_st = rot_ce_stream_dict[key].copy()\n",
    "    obs_st.sort()\n",
    "    syn_st = esyn_dict[key].copy()\n",
    "    for i in range(len(obs_st)):\n",
    "        print('syn.station,real.station = (%s,%s)' %(syn_st[i].stats.station,obs_st[i].stats.station))\n",
    "        print('syn.starttime  = %s' %(syn_st[i].stats.starttime))\n",
    "        print('real.starttime = %s' %(obs_st[i].stats.starttime))\n",
    "        print('syn.endtime    = %s' %(syn_st[i].stats.endtime))\n",
    "        print('real.endtime   = %s' %(obs_st[i].stats.endtime))\n",
    "        print('syn.delta      = %s' %(syn_st[i].stats.delta))\n",
    "        print('real.delta     = %s' %(obs_st[i].stats.delta))\n",
    "        print('syn.len        = %s' %(len(syn_st[i].data)))\n",
    "        print('real.len       = %s' %(len(obs_st[i].data)))\n",
    "        start_t = obs_st[i].stats.starttime\n",
    "        end_t   = syn_st[i].stats.endtime\n",
    "        obs_st[i] = obs_st[i].slice(start_t,end_t)\n",
    "        syn_st[i] = syn_st[i].slice(start_t,end_t)\n",
    "        print('sliced syn.starttime   = %s' %(syn_st[i].stats.starttime))\n",
    "        print('sliced real.starttime  = %s' %(obs_st[i].stats.starttime))\n",
    "        print('sliced syn.endtime     = %s' %(syn_st[i].stats.endtime))\n",
    "        print('sliced real.endtime    = %s' %(obs_st[i].stats.endtime))\n",
    "        #FIXME: machine epsilon issue? Mitigation below\n",
    "        syn_st[i].stats.starttime = obs_st[i].stats.starttime\n",
    "        print('sliced syn.starttime   = %s' %(syn_st[i].stats.starttime))\n",
    "        print('sliced syn.endtime     = %s' %(syn_st[i].stats.endtime))\n",
    "        print('sliced syn.delta       = %s' %(syn_st[i].stats.delta))\n",
    "        print('sliced real.delta      = %s' %(obs_st[i].stats.delta))\n",
    "        print('sliced syn.len         = %s' %(len(syn_st[i].data)))\n",
    "        print('sliced real.len        = %s' %(len(obs_st[i].data)))\n",
    "        print('sliced syn.times()[0]  = %s' %(syn_st[i].times()[0]))\n",
    "        print('sliced real.times()[0] = %s' %(obs_st[i].times()[0]))\n",
    "        print('sliced syn.times()[-1]  = %s' %(syn_st[i].times()[-1]))\n",
    "        print('sliced real.times()[-1] = %s' %(obs_st[i].times()[-1]))\n",
    "        print()\n",
    "        print()\n",
    "    reg_obs_st_dict[key] = obs_st\n",
    "    reg_syn_st_dict[key] = syn_st\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Signal to Noise -win to +win (s) of Trigger Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_s2n_ratio_power_4tr(tr,triggers,win):\n",
    "    \n",
    "        \n",
    "        p_0 = triggers[1]\n",
    "        dt  = tr.stats.delta\n",
    "        assert 0 < dt\n",
    "        \n",
    "        ip_0 = int(p_0/dt)\n",
    "        nwin = int(win/dt)\n",
    "        assert 0 < nwin\n",
    "        i_rwin = ip_0 + nwin + 1\n",
    "        i_lwin = ip_0 - nwin\n",
    "        \n",
    "        if i_lwin < 0:\n",
    "            i_lwin = 0\n",
    "        \n",
    "        lsum = np.sum(tr.data[i_lwin:ip_0]**2)\n",
    "        lsum /= nwin\n",
    "        \n",
    "        rsum = np.sum(tr.data[ip_0+1:i_rwin]**2)\n",
    "        rsum /= nwin\n",
    "        \n",
    "        ratio = 1000000\n",
    "        if lsum != 0:\n",
    "            ratio = rsum/lsum\n",
    "        \n",
    "        return (ratio, tr.times()[i_lwin], tr.times()[i_rwin])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Plotting Function for Comparison of Obs vs Syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_obs_v_syn(ekey,obs_st,syn_st,trig_dict,comp,f1,f2,plt_h,plt_w,win=0.5,fname=None):\n",
    "    \n",
    "    assert len(obs_st) == len(syn_st)\n",
    "    \n",
    "    assert comp == 'X' or comp == 'Y' or comp == 'Z'\n",
    "    \n",
    "    icomp = 0\n",
    "    if comp == 'Y':\n",
    "        icomp = 1\n",
    "    if comp == 'Z':\n",
    "        icomp = 2\n",
    "    \n",
    "    c_obs_st = obs_st.copy()\n",
    "    c_syn_st = syn_st.copy()\n",
    "\n",
    "    c_obs_st.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "    c_syn_st.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "    \n",
    "    ntrace = len(c_obs_st)//3\n",
    "\n",
    "    plt_scale = int(ntrace)\n",
    "    fig, ax = plt.subplots(plt_scale,figsize=(plt_w,plt_h*plt_scale))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    for i in range(ntrace):\n",
    "        itr = 3*i + icomp\n",
    "        \n",
    "        triggers = trig_dict[c_obs_st[itr].stats.station]\n",
    "        #print('event %d: trig %s:' %(ekey,c_obs_st[itr].stats.station), np.array(triggers[:]))\n",
    "        \n",
    "        p_trig = triggers[0]\n",
    "        p_0    = triggers[1]\n",
    "        s_0 = triggers[2]\n",
    "        s_trig = triggers[3]\n",
    "        \n",
    "        s2n, lwt, rwt = calc_s2n_ratio_power_4tr(c_obs_st[itr],triggers,win)\n",
    "\n",
    "        omin = np.min(c_obs_st[itr].data)\n",
    "        omax = np.max(c_obs_st[itr].data)\n",
    "        onorm = 1.0/np.max([np.abs(omin),np.abs(omax)])\n",
    "        #onorm = 1.0\n",
    "        o_pdata = np.zeros_like(c_obs_st[itr].data)\n",
    "        o_pdata[:] = onorm*c_obs_st[itr].data[:]\n",
    "        \n",
    "        smin = np.min(c_syn_st[itr].data)\n",
    "        smax = np.max(c_syn_st[itr].data)\n",
    "        snorm = 1.0/np.max([np.abs(smin),np.abs(smax)])\n",
    "        #snorm = 1.0\n",
    "        s_pdata = np.zeros_like(c_syn_st[itr].data)\n",
    "        s_pdata[:] = snorm*c_syn_st[itr].data[:]\n",
    "        \n",
    "        amin = np.min(np.array([np.min(o_pdata),np.min(s_pdata)]))\n",
    "        amax = np.max(np.array([np.max(o_pdata),np.max(s_pdata)]))\n",
    "\n",
    "        t = c_obs_st[itr].times()\n",
    "        ax[i].plot(t, o_pdata,c='black',label='obs',zorder=1)\n",
    "        ax[i].plot(t, s_pdata,c='green',label='syn',zorder=0)\n",
    "        \n",
    "        ax[i].vlines(x=p_0, ymin=amin, ymax=amax, colors='red',linestyle='dashed')\n",
    "        ax[i].vlines(x=p_trig, ymin=amin, ymax=amax, colors='red')\n",
    "        ax[i].vlines(x=s_0, ymin=amin, ymax=amax, colors='blue',linestyle='dashed')\n",
    "        ax[i].vlines(x=s_trig, ymin=amin, ymax=amax, colors='blue')\n",
    "        if win != None:\n",
    "            ax[i].axvspan(lwt, p_0, label='pre P-arrival',color=\"red\", alpha=0.2)\n",
    "            ax[i].axvspan(p_0, rwt, label='post P-arrival',color=\"blue\", alpha=0.2)\n",
    "\n",
    "        station = c_obs_st[itr].stats.station\n",
    "        station += '.' + c_obs_st[itr].stats.channel\n",
    "\n",
    "        overlay_title = 'Event: %d,  Station.Channel-%s: @%d-%dHz,  SNR: %.2f' %(ekey,str(station),int(f1),int(f2),s2n)\n",
    "        ax[i].set_title(overlay_title)\n",
    "        ax[i].legend()\n",
    "\n",
    "        ax[i].grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "        ax[i].minorticks_on()\n",
    "        ax[i].grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "        \n",
    "        \n",
    "    if fname != None:\n",
    "        assert win != None\n",
    "        ofname = '%s_%s_%d-%dHz_s2n%.1f_w%.2f.png' %(fname,str(station),int(f1),int(f2),s2n,win)\n",
    "        fig.savefig(ofname, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Obs vs Syn for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekey = 3\n",
    "obs_st = reg_obs_st_dict[ekey]\n",
    "syn_st = reg_syn_st_dict[ekey]\n",
    "trig_dict = event_trigger_dict[ekey]\n",
    "f1 = 4.0\n",
    "f2 = 16.0\n",
    "plt_h = 2\n",
    "plt_w = 14\n",
    "xcomp = 'X'\n",
    "ycomp = 'Y'\n",
    "zcomp = 'Z'\n",
    "#print(trig_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare X-component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obs_v_syn(ekey,obs_st,syn_st,trig_dict,xcomp,f1,f2,plt_h,plt_w,win=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Y-component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obs_v_syn(ekey,obs_st,syn_st,trig_dict,ycomp,f1,f2,plt_h,plt_w,win=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Z-component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_obs_v_syn(ekey,obs_st,syn_st,trig_dict,zcomp,f1,f2,plt_h,plt_w,win=1.0,fname='Event-%d'%(ekey))\n",
    "plot_obs_v_syn(ekey,obs_st,syn_st,trig_dict,zcomp,f1,f2,plt_h,plt_w,win=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function to create dictionary of SNRs to be use for removing stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_obs_st = obs_st.copy()\n",
    "print('Before:', c_obs_st[0:3])\n",
    "f_obs_st = obs_st.copy()\n",
    "x_st = f_obs_st.select(component='X')\n",
    "y_st = f_obs_st.select(component='Y')\n",
    "z_st = f_obs_st.select(component='Z')\n",
    "\n",
    "ntrace = len(x_st)\n",
    "\n",
    "for i in range(ntrace):\n",
    "    \n",
    "    x_tr = x_st[i]\n",
    "    y_tr = y_st[i]\n",
    "    z_tr = z_st[i]\n",
    "    \n",
    "    xstation = x_tr.stats.station\n",
    "    ystation = y_tr.stats.station\n",
    "    zstation = z_tr.stats.station\n",
    "    \n",
    "    assert xstation == ystation and xstation == zstation\n",
    "    \n",
    "    if xstation == 'G013':\n",
    "        c_obs_st.remove(x_tr)\n",
    "        c_obs_st.remove(y_tr)\n",
    "        c_obs_st.remove(z_tr)\n",
    "    \n",
    "print('Before:', c_obs_st[0:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_traces_by_snr(ekey,obs_st,trig_dict,f1,f2,plt_h,plt_w,win=1.0,z_snr_thold=10.0,x_snr_thold=5.0,y_snr_thold=5.0):\n",
    "    \n",
    "    f_obs_st = obs_st.copy()\n",
    "    k_obs_st = obs_st.copy()\n",
    "    r_obs_st = Stream()\n",
    "    \n",
    "    x_st = obs_st.select(component='X')\n",
    "    y_st = obs_st.select(component='Y')\n",
    "    z_st = obs_st.select(component='Z')\n",
    "\n",
    "    f_obs_st.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "    f_x_st = f_obs_st.select(component='X')\n",
    "    f_y_st = f_obs_st.select(component='Y')\n",
    "    f_z_st = f_obs_st.select(component='Z')\n",
    "    \n",
    "    assert len(f_x_st) == len(f_y_st) and len(f_x_st) == len(f_z_st)\n",
    "    assert len(x_st) == len(y_st) and len(x_st) == len(z_st)\n",
    "    assert len(f_x_st) == len(x_st)\n",
    "    \n",
    "    ntrace = len(f_x_st)\n",
    "    \n",
    "    keep_dict   = {}\n",
    "    remove_dict = {}\n",
    "\n",
    "    for i in range(ntrace):\n",
    "            \n",
    "        x_tr = x_st[i]\n",
    "        y_tr = y_st[i]\n",
    "        z_tr = z_st[i]\n",
    "\n",
    "        xstation = x_tr.stats.station\n",
    "        ystation = y_tr.stats.station\n",
    "        zstation = z_tr.stats.station\n",
    "        \n",
    "        xchan = x_tr.stats.channel\n",
    "        ychan = y_tr.stats.channel\n",
    "        zchan = z_tr.stats.channel\n",
    "\n",
    "        assert xstation == ystation and xstation == zstation\n",
    "\n",
    "        triggers = trig_dict[xstation]\n",
    "\n",
    "        p_trig = triggers[0]\n",
    "        p_0    = triggers[1]\n",
    "        s_0 = triggers[2]\n",
    "        s_trig = triggers[3]\n",
    "\n",
    "        x_s2n, lwt, rwt = calc_s2n_ratio_power_4tr(f_x_st[i],triggers,win)\n",
    "        y_s2n, lwt, rwt = calc_s2n_ratio_power_4tr(f_y_st[i],triggers,win)\n",
    "        z_s2n, lwt, rwt = calc_s2n_ratio_power_4tr(f_z_st[i],triggers,win)\n",
    "\n",
    "        if z_s2n < z_snr_thold or x_s2n < x_snr_thold or y_s2n < y_snr_thold:\n",
    "            print()\n",
    "            print('Removing Station: %s' %(xstation))\n",
    "            print('x_s2n:',x_s2n)\n",
    "            print('y_s2n:',y_s2n)\n",
    "            print('z_s2n:',z_s2n)\n",
    "            remove_dict[xstation + '.' + xchan] = x_s2n\n",
    "            remove_dict[ystation + '.' + ychan] = y_s2n\n",
    "            remove_dict[zstation + '.' + zchan] = z_s2n\n",
    "            k_obs_st.remove(x_tr)\n",
    "            k_obs_st.remove(y_tr)\n",
    "            k_obs_st.remove(z_tr)\n",
    "            r_obs_st += x_st[i]\n",
    "            r_obs_st += y_st[i]\n",
    "            r_obs_st += z_st[i]\n",
    "        else:\n",
    "            keep_dict[xstation + '.' + xchan] = x_s2n\n",
    "            keep_dict[ystation + '.' + ychan] = y_s2n\n",
    "            keep_dict[zstation + '.' + zchan] = z_s2n\n",
    "            \n",
    "    return (k_obs_st.sort(),r_obs_st.sort(),keep_dict,remove_dict)\n",
    "\n",
    "c_obs_st = obs_st.copy()\n",
    "print('Before:', c_obs_st[0:3])\n",
    "print('Before:', len(c_obs_st))\n",
    "k_st,r_st,k_dict,r_dict = remove_traces_by_snr(ekey,c_obs_st,trig_dict,f1,f2,plt_h,plt_w,win=1.0)\n",
    "print()\n",
    "print('After Keep: ', k_st[0:3])\n",
    "print('After Keep: ', len(k_st))\n",
    "print()\n",
    "print('After Remo: ', r_st[0:3])\n",
    "print('After Remo: ', len(r_st))\n",
    "print()\n",
    "#print('Keep:\\n',k_dict)\n",
    "#print('Remo:\\n',r_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Signal to Noise -0.75s to +0.75s of Trigger Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_s2n_ratio_power(ekey,obs_st,trig_dict,comp,win,f1,f2):\n",
    "    \n",
    "    assert comp == 'X' or comp == 'Y' or comp == 'Z'\n",
    "    \n",
    "    s2n_dict = {}\n",
    "    \n",
    "    icomp = 0\n",
    "    if comp == 'Y':\n",
    "        icomp = 1\n",
    "    if comp == 'Z':\n",
    "        icomp = 2\n",
    "    \n",
    "    c_obs_st = obs_st.copy()\n",
    "\n",
    "    c_obs_st.filter('bandpass',freqmin=f1,freqmax=f2,corners=4,zerophase=True)\n",
    "    \n",
    "    ntrace = len(c_obs_st)//3\n",
    "\n",
    "    for i in range(ntrace):\n",
    "        itr = 3*i + icomp\n",
    "        \n",
    "        s_key = c_obs_st[itr].stats.station\n",
    "        c_key = c_obs_st[itr].stats.channel\n",
    "        tr_key = s_key + '.' + c_key\n",
    "        triggers = trig_dict[s_key]\n",
    "        #print('event %d: trig %s:' %(ekey,c_obs_st[itr].stats.station), np.array(triggers[:]))\n",
    "        \n",
    "        p_0    = triggers[1]\n",
    "        dt = c_obs_st[itr].stats.delta\n",
    "        \n",
    "        ip_0 = int(p_0/dt)\n",
    "        nwin = int(win/dt)\n",
    "        i_rwin = ip_0 + nwin + 1\n",
    "        i_lwin = ip_0 - nwin\n",
    "        \n",
    "        if i_lwin < 0:\n",
    "            i_lwin = 0\n",
    "        \n",
    "        #print('left win len: ',len(c_obs_st[itr].data[i_lwin:ip_0]))\n",
    "        lsum = np.sum(c_obs_st[itr].data[i_lwin:ip_0]**2)\n",
    "        lsum /= nwin\n",
    "        \n",
    "        #print('right win len:',len(c_obs_st[itr].data[ip_0+1:i_rwin]))\n",
    "        rsum = np.sum(c_obs_st[itr].data[ip_0+1:i_rwin]**2)\n",
    "        rsum /= nwin\n",
    "        \n",
    "        s2n_dict[tr_key] = rsum/lsum\n",
    "        \n",
    "    return s2n_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 1 #seconds\n",
    "f1 = 2.0\n",
    "f2 = 6.0\n",
    "s2n = calc_s2n_ratio_power(ekey,obs_st,trig_dict,'Z',win,f1,f2)\n",
    "print('s2n:\\n',s2n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
