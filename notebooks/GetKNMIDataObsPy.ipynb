{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a client object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "import numpy as np\n",
    "\n",
    "client = Client(\"IRIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy \n",
    "from obspy import UTCDateTime\n",
    "\n",
    " #= UTCDateTime(\"2010-02-27T06:45:00.000\")\n",
    "t = obspy.UTCDateTime('%04d-%02d-%02dT00:00:00.0000' % (2015, 3, 29))\n",
    "#t1 = obspy.UTCDateTime('%04d-%02d-%02dT00:00:00.0000' % (year, month, day))\n",
    "\n",
    "#st = client.get_waveforms(\"IU\", \"ANMO\", \"00\", \"LH1\", t, t + 60 * 60)\n",
    "st = client.get_waveforms(\"IU\", \"ANMO\", \"00\", \"LH1\", t, t + 60 * 60)\n",
    "\n",
    "\n",
    "st.plot()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = UTCDateTime(\"2002-01-01\")\n",
    "endtime = UTCDateTime(\"2002-01-02\")\n",
    "\n",
    "cat = client.get_events(starttime=starttime, endtime=endtime, minmagnitude=6, catalog=\"ISC\")\n",
    "\n",
    "#print(cat)\n",
    "print(vars(cat[0]))\n",
    "print()\n",
    "print('mags:',cat[0]['magnitudes'])\n",
    "\n",
    "#for i in cat:\n",
    "    #print(vars(i))\n",
    "    \n",
    "#print(np.log(1665579))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current FDSN Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn.header import URL_MAPPINGS\n",
    "\n",
    "for key in sorted(URL_MAPPINGS.keys()):\n",
    "\n",
    "    print(\"{0:<11} {1}\".format(key,  URL_MAPPINGS[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get KNMI clinet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct clinet using URL Key\n",
    "client = Client('KNMI')\n",
    "print(client)\n",
    "print()\n",
    "\n",
    "# Construct clinet using URL\n",
    "client2 = Client('http://rdsa.knmi.nl')\n",
    "print(client2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Waveform (Author: Rhys, Edited: Thomas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_event_data(network, station, channel, origin, window, pfilt=None):\n",
    "\n",
    "    client = Client('KNMI')\n",
    "    #client = Client('http://rdsa.knmi.nl')\n",
    "\n",
    "    t1 = origin\n",
    "    t2 = t1 + window//200 + 1\n",
    "\n",
    "    st = client.get_waveforms(network = network,\n",
    "                              station = station,\n",
    "                              location = '',\n",
    "                              channel = channel,\n",
    "                              starttime = t1,\n",
    "                              endtime = t2,\n",
    "                              attach_response = True)\n",
    "\n",
    "    st.detrend(type = 'demean')\n",
    "\n",
    "    if pfilt:\n",
    "        st.remove_response(pre_filt = pfilt)\n",
    "    else:\n",
    "        st.remove_response()\n",
    "\n",
    "    return st\n",
    "\n",
    "#my_prefilt = (0.4, 0.5, 25.0, 27.5)\n",
    "my_prefilt = (0.4, 0.5, 45.0, 47.5)\n",
    "\n",
    "#t1 = obspy.UTCDateTime('20190609T05:00:15.0')\n",
    "t1 = obspy.UTCDateTime('20190522T03:49:00.5') - 5*60\n",
    "print(\"TYPE:\", type(t1))\n",
    "\n",
    "s = get_event_data('NL', 'G343', 'HHZ', t1, 16384, my_prefilt)\n",
    "s_str = str(s[0])\n",
    "print(\"S:\",s)\n",
    "print(\"vars(S):\",vars(s))\n",
    "print(\"S.str:\",s_str)\n",
    "r = get_event_data('NL', 'G343', 'HH2', t1, 16384, my_prefilt)\n",
    "#s = get_event_data('NL', 'G340', 'HGZ', t1, 16384)\n",
    "#r = get_event_data('NL', 'G340', 'HG2', t1, 16384)\n",
    "#r = get_event_data('NL', 'G341', 'HHZ', t1, 16384)\n",
    "\n",
    "starttime = max(s[0].stats.starttime, r[0].stats.starttime)\n",
    "endtime = min(s[0].stats.endtime, r[0].stats.endtime)\n",
    "\n",
    "s.trim(starttime, endtime)\n",
    "r.trim(starttime, endtime)\n",
    "\n",
    "#print(s[0].data.size, r[0].data.size)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "signal = s[0].data\n",
    "t = np.arange(signal.size, dtype = 'float')/200.0\n",
    "\n",
    "ax.plot(t, signal)\n",
    "\n",
    "\n",
    "signal = r[0].data\n",
    "t = np.arange(signal.size, dtype = 'float')/200.0\n",
    "\n",
    "ax.plot(t, signal)\n",
    "\n",
    "#A = np.fft.rfft(s[0].data[:16384])\n",
    "#B = np.fft.rfft(r[0].data[:16384])\n",
    "\n",
    "#freq = np.fft.rfftfreq(16384, 1.0/200.0)\n",
    "\n",
    "#fig, ax = plt.subplots(2)\n",
    "\n",
    "#ax[0].plot(freq, np.abs(A))\n",
    "#ax[1].plot(freq, np.abs(B))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Station Metadata (Author: Rhys, Edited: Thomas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import argparse\n",
    "\n",
    "def get_station_meta(network, station, FDSN):\n",
    "\n",
    "    #FDSN = 'http://rdsa.knmi.nl/fdsnws/station/1/query'\n",
    "    parameters = {'network': network,\n",
    "                  'station': station,\n",
    "                  'level': 'channel',\n",
    "                  #'format': 'xml',\n",
    "                  'format': 'text',\n",
    "                  'nodata': '404'}\n",
    "\n",
    "    resp = requests.get(FDSN, parameters)\n",
    "\n",
    "    if (resp.status_code == 404):\n",
    "        return None\n",
    "\n",
    "    print(resp.url)\n",
    "    return resp.text\n",
    "# end get_station_meta()\n",
    "\n",
    "myFDSN = 'http://rdsa.knmi.nl/fdsnws/station/1/query'\n",
    "myNetwork = 'NL'\n",
    "myStation = 'G431'\n",
    "\n",
    "t = get_station_meta(myNetwork, myStation, myFDSN)\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get events of Magnitude 2 and greaters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#%matplotlib notebook off\n",
    "#starttime = UTCDateTime(\"2002-01-01\")\n",
    "#endtime = UTCDateTime(\"2018-01-02\")\n",
    "\n",
    "#cat = client.get_events(starttime=starttime, endtime=endtime,  minmagnitude=1, catalog=\"KNMI\")\n",
    "#cat = client.get_events(starttime=starttime, endtime=endtime, catalog=\"ISC\")\n",
    "cat = client.get_events(minmagnitude=1.0)\n",
    "\n",
    "print(len(cat))\n",
    "print(cat)\n",
    "print()\n",
    "\n",
    "ic = 0\n",
    "nneth = 0\n",
    "nsouth = 0\n",
    "for c in cat:\n",
    "    if len(c.event_descriptions) != 1:\n",
    "        if c.event_descriptions[1]['text'] == 'The Netherlands':\n",
    "            nneth += 1\n",
    "            if c.origins[0].earth_model_id == None:\n",
    "                print()\n",
    "                print()\n",
    "                print(\"NONE TYPE FOUND!!\")\n",
    "                print()\n",
    "                print()\n",
    "                continue;\n",
    "            \n",
    "            nloc = c.origins[0].earth_model_id.id.find('Northern') \n",
    "            if nloc < 0:\n",
    "                nsouth += 1\n",
    "                #print('Event %d:' %(ic),c)\n",
    "                #print()\n",
    "                #print('type:', type(c))\n",
    "                #print()\n",
    "                #print('c.foc:', c.magnitudes)\n",
    "                #print()\n",
    "                ##print('c.e_desc:', len(c.event_descriptions))\n",
    "                #print('c.e_desc:', c.event_descriptions[1]['text'])\n",
    "                #print()\n",
    "                #print('len(c.origins):', len(c.origins[0]))\n",
    "                #print('c.origins.emi:', c.origins[0].earth_model_id)\n",
    "                #print('type(c.origins.emi):', type(c.origins[0].earth_model_id))\n",
    "                #print('vars(c.origins.emi):', vars(c.origins[0].earth_model_id))\n",
    "                #print('c.origins.emi.id:', c.origins[0].earth_model_id.id)\n",
    "                #print('type(c.origins.emi.id):', type(c.origins[0].earth_model_id.id))\n",
    "                #nloc = c.origins[0].earth_model_id.id.find('Netherlands') \n",
    "                #print('nloc:', nloc)\n",
    "                #nstr = c.origins[0].earth_model_id.id[nloc:]\n",
    "                #print('nstr:', nstr)\n",
    "                #print()\n",
    "                #for e in c:\n",
    "                    #print('element:', e)\n",
    "                    #print('value:', c[e])\n",
    "                    #print()\n",
    "    ic += 1\n",
    "\n",
    "print('Number of Netherlands Quakes:',nneth)\n",
    "print('Number of Southern Netherlands Quakes:',nsouth)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def count_eNL_by_loc(_cat, _locstr):\n",
    "    cnone = 0\n",
    "    onee = 0\n",
    "    nnl = 0\n",
    "    nmatch = 0\n",
    "    nmis = 0\n",
    "    for ic in range(len(_cat)):\n",
    "        if _cat[ic].origins[0].earth_model_id is None:\n",
    "            cnone += 1\n",
    "            print()\n",
    "            print('!!!!! Found NONETYPE !!!!!')\n",
    "            print()\n",
    "            continue\n",
    "        if len(_cat[ic].event_descriptions) == 1:\n",
    "            onee += 1\n",
    "            continue\n",
    "        else:\n",
    "            if _cat[ic].event_descriptions[1]['text'] == 'The Netherlands':\n",
    "                nnl += 1\n",
    "                nloc_n = _cat[ic].origins[0].earth_model_id.id.find('North') \n",
    "                nloc_nern = _cat[ic].origins[0].earth_model_id.id.find('Northern') \n",
    "                nloc_s = _cat[ic].origins[0].earth_model_id.id.find('South') \n",
    "                nloc_sern = _cat[ic].origins[0].earth_model_id.id.find('Southern') \n",
    "                if 0 <= nloc_nern:\n",
    "                    if nloc_n == -1:\n",
    "                        print()\n",
    "                        print('!!!! NORTH is not NORTHERN  !!!!')\n",
    "                        print()\n",
    "                if 0 <= nloc_sern:\n",
    "                    if nloc_s == -1:\n",
    "                        print()\n",
    "                        print('!!!! SOUTH is not SOUTHERN  !!!!')\n",
    "                        print()\n",
    "                #if (nloc_n == -1) and (nloc_nern == -1) and (nloc_s == -1) and (nloc_sern == -1):\n",
    "                    #print(\"Missed:\", _cat[ic].origins[0].earth_model_id.id)\n",
    "                    #print(\"Missed From:\", _cat[ic].event_descriptions[1]['text'])\n",
    "                    #nmis += 1\n",
    "                nloc = _cat[ic].origins[0].earth_model_id.id.find(_locstr) \n",
    "                if 0 <= nloc:\n",
    "                    nmatch += 1\n",
    "    print('Number Missed:', nmis)\n",
    "    return (cnone,onee,nnl,nmatch)\n",
    "\n",
    "cat = client.get_events(minmagnitude=1.0)\n",
    "\n",
    "n_north = count_eNL_by_loc(cat,'North')\n",
    "n_northern = count_eNL_by_loc(cat,'Northern')\n",
    "n_south = count_eNL_by_loc(cat,'South')\n",
    "n_southern = count_eNL_by_loc(cat,'Southern')\n",
    "\n",
    "print('          None  OneE  nNL    nMatch')\n",
    "print('North:    %d    %d     %d   %d' %(n_north))\n",
    "print('Northern: %d    %d     %d   %d' %(n_northern))\n",
    "print('South:    %d    %d     %d   %d' %(n_south))\n",
    "print('Southern: %d    %d     %d   %d' %(n_southern))\n",
    "\n",
    "print(\"NL Total:\", n_north[3] + n_south[3])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#def getNorthOnlyCat(_cat):\n",
    "#    mycat = _cat\n",
    "#    for ic in range(len(mycat)):\n",
    "#        \n",
    "#        if mycat[ic].origins[0].earth_model_id is None:\n",
    "#            del mycat[ic]\n",
    "#            continue\n",
    "#            \n",
    "#        if len(mycat[ic].event_descriptions) == 1:\n",
    "#            del mycat[ic]\n",
    "#            continue\n",
    "#            \n",
    "#        if mycat[ic].event_descriptions[1]['text'] != 'The Netherlands':\n",
    "#            del mycat[ic]\n",
    "#            continue\n",
    "#            \n",
    "#        nloc_n = mycat[ic].origins[0].earth_model_id.id.find('North') \n",
    "#        if nloc_n == -1:\n",
    "#            del mycat[ic]\n",
    "#            \n",
    "#    return mycat\n",
    "    #end getNorthOnlyCat()\n",
    "    \n",
    "def getNorthOnlyCat(_cat):\n",
    "    \n",
    "    nrem = 0\n",
    "    lrem = []\n",
    "    \n",
    "    for ic in range(len(_cat)):\n",
    "        if _cat[ic].origins[0].earth_model_id is None:\n",
    "            lrem.append(ic)\n",
    "            nrem += 1\n",
    "            continue\n",
    "            \n",
    "        if len(_cat[ic].event_descriptions) == 1:\n",
    "            lrem.append(ic)\n",
    "            nrem += 1\n",
    "            continue\n",
    "            \n",
    "        if _cat[ic].event_descriptions[1]['text'] != 'The Netherlands':\n",
    "            lrem.append(ic)\n",
    "            nrem += 1\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            nloc_n = _cat[ic].origins[0].earth_model_id.id.find('North') \n",
    "            if nloc_n == -1:\n",
    "                lrem.append(ic)\n",
    "                nrem += 1\n",
    "                continue\n",
    "            \n",
    "    print('Num Removed:', nrem)\n",
    "    for rem in lrem[::-1]:\n",
    "        del _cat[rem]\n",
    "            \n",
    "cat = client.get_events(minmagnitude=1.0)\n",
    "print(len(cat))\n",
    "getNorthOnlyCat(cat)\n",
    "print(len(cat))\n",
    "\n",
    "\n",
    "#ncat = getNorthOnlyCat(cat)\n",
    "#print(cat)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ievent = cat[2]\n",
    "for i in ievent:\n",
    "    print(i)\n",
    "print()\n",
    "\n",
    "print('foc:',ievent['focal_mechanisms'])\n",
    "print\n",
    "\n",
    "print(ievent['magnitudes'][0])\n",
    "print()\n",
    "\n",
    "print('type:',type(ievent['magnitudes']))\n",
    "print()\n",
    "\n",
    "print('vars:',vars(ievent['magnitudes'][0]))\n",
    "print()\n",
    "\n",
    "print('mag?:',vars(ievent['magnitudes'][0]))\n",
    "print()\n",
    "\n",
    "for i in ievent['magnitudes']:\n",
    "    print('i:',i)\n",
    "    print('i-type:',type(i))\n",
    "    print('i-vars:',vars(i))\n",
    "    print('i-mag:',i['mag'])\n",
    "    print()\n",
    "\n",
    "#for i in cat:\n",
    "    #print(i['magnitudes'][0])\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnam.events.gevents import gevents as gevents\n",
    "\n",
    "enorth = gevents(3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "ocat = enorth.getOrigCatalog()\n",
    "ncat = enorth.getIncCatalog()\n",
    "ccat = enorth.getExcCatalog()\n",
    "\n",
    "print(len(ocat))\n",
    "print(len(ncat))\n",
    "print(len(ccat))\n",
    "print(ncat)\n",
    "print(type(ncat))\n",
    "#ncat.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_data(network, station, channel, origin, window, pfilt=None):\n",
    "\n",
    "    client = Client('KNMI')\n",
    "    #client = Client('http://rdsa.knmi.nl')\n",
    "\n",
    "    t1 = origin\n",
    "    t2 = t1 + window//200 + 1\n",
    "\n",
    "    st = client.get_waveforms(network = network,\n",
    "                              station = station,\n",
    "                              location = '',\n",
    "                              channel = channel,\n",
    "                              starttime = t1,\n",
    "                              endtime = t2,\n",
    "                              attach_response = True)\n",
    "\n",
    "    st.detrend(type = 'demean')\n",
    "\n",
    "    if pfilt:\n",
    "        st.remove_response(pre_filt = pfilt)\n",
    "    else:\n",
    "        st.remove_response()\n",
    "\n",
    "    return st"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import obspy \n",
    "import numpy as np\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import Stream\n",
    "\n",
    "#origin = event.origins[0]\n",
    "#t = origin.time\n",
    "#\n",
    "#inventory = client.get_stations(longitude=origin.longitude, latitude=origin.latitude,\n",
    "                                #minradius=101, maxradius=103,\n",
    "                                #starttime=t, endtime =t+100,\n",
    "                                #channel=\"LHZ\", level=\"response\",\n",
    "                                #matchtimeseries=True)\n",
    "\n",
    "stations = 'G0*3,G0*4,G1*3,G1*4,G2*3,G2*4,G3*3,G3*4,G4*3,G4*4,G5*3,G5*4,G6*3,G6*4,G70*3,G70*4'\n",
    "client = Client(\"KNMI\")\n",
    "inventory = client.get_stations(network=\"NL\", station=stations , level=\"response\")\n",
    "#inventory = client.get_stations(network=\"NL\", station='*' , level=\"response\")\n",
    "print('Inventory Size:',len(inventory))\n",
    "print('Inventory Type:',type(inventory))\n",
    "\n",
    "my_prefilt = (0.4, 0.5, 45.0, 47.5)\n",
    "\n",
    "\n",
    "stz = Stream()\n",
    "st1 = Stream()\n",
    "st2 = Stream()\n",
    "\n",
    "ne = 0\n",
    "for c in ncat:\n",
    "    print('Event:',ne)\n",
    "    t1 = c.origins[0].time\n",
    "    t2 = t1 + 16384//200 + 1\n",
    "    ot1 = c.creation_info['creation_time']\n",
    "    print('t1: ', t1)\n",
    "    print('ot1:', ot1)\n",
    "    print('Year: ', t1.year)\n",
    "    print('StreamZ:\\n',stz)\n",
    "    print('Stream1:\\n',st1)\n",
    "    print('Stream2:\\n',st2)\n",
    "    if t1.year < 2016:\n",
    "        print('Data is too old for the FDSN data at KNMI')\n",
    "        continue\n",
    "    for network in inventory:\n",
    "        print('Network Size:',len(network))\n",
    "        for station in network:\n",
    "            try:\n",
    "                # Z component\n",
    "                stz += client.get_waveforms(network.code, station.code, \"*\", \"HHZ\",\n",
    "                                           t1, t1 + 60, attach_response = True)\n",
    "                \n",
    "                # Northish component\n",
    "                st1 += client.get_waveforms(network.code, station.code, \"*\", \"HH1\",\n",
    "                                           t1, t1 + 60, attach_response = True)\n",
    "                \n",
    "                # Eastish component\n",
    "                st2 += client.get_waveforms(network.code, station.code, \"*\", \"HH2\",\n",
    "                                           t1, t1 + 60, attach_response = True)\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    ne += 1\n",
    "\n",
    "print('Num StreamZ:',len(stz))\n",
    "print('Num Stream1:',len(st1))\n",
    "print('Num Stream2:',len(st2))\n",
    "\n",
    "print('Detrending and Removing Response')\n",
    "#stz.detrend(type='demean')\n",
    "#stz.remove_response()\n",
    "#st1.detrend(type='demean')\n",
    "#st1.remove_response()\n",
    "#st2.detrend(type='demean')\n",
    "#st2.remove_response()\n",
    "    \n",
    "#stz.plot()\n",
    "#st1.plot()\n",
    "#st2.plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnam.events.gevents import gevents as gevents\n",
    "from gnam.events.gstations import gstations as gstations\n",
    "import pickle\n",
    "\n",
    "f = open('./model_bbox.pickle', 'rb')\n",
    "gf_bbox = pickle.load(f)\n",
    "f.close()\n",
    "print('bbox after pickle :\\n',gf_bbox)\n",
    "\n",
    "enorth = gevents(2.0,gf_bbox)\n",
    "print(enorth)\n",
    "\n",
    "snorth = gstations(enorth,tend=16.384)\n",
    "print(snorth)\n",
    "\n",
    "#print('Runtime:', snorth.getSetupTime())\n",
    "\n",
    "f = open('./enorth.pickle', 'wb')\n",
    "pickle.dump(enorth, f)\n",
    "f.close()\n",
    "\n",
    "f = open('./gevents_test2.pickle', 'wb')\n",
    "pickle.dump(snorth, f)\n",
    "f.close()\n",
    "'''\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnam.events.gevents import gevents as gevents\n",
    "from gnam.events.gstations import gstations as gstations\n",
    "import pickle\n",
    "\n",
    "f = open('./model_bbox.pickle', 'rb')\n",
    "gf_bbox = pickle.load(f)\n",
    "f.close()\n",
    "print('bbox after pickle :\\n',gf_bbox)\n",
    "\n",
    "f = open('./enorth.pickle', 'rb')\n",
    "enorth = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('./gevents_test2.pickle', 'rb')\n",
    "dill_snorth = pickle.load(f)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "from gnam.events.munge.knmi import correct_station_depths as csd_f\n",
    "import shapefile as sf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "mysf = sf.Reader('FieldShapeFile/Groningen_field')\n",
    "print('mysf:',mysf)\n",
    "print('mysf.shapes():',mysf.shapes())\n",
    "s = mysf.shape(0)\n",
    "\n",
    "shape_xy = np.asarray(s.points)\n",
    "print(shape_xy)\n",
    "\n",
    "#correct the knmi station depths\n",
    "dill_snorth.correct_stations(csd_f)\n",
    "\n",
    "\n",
    "ekeys = dill_snorth.getEventKeys()\n",
    "print(ekeys)\n",
    "bkeys = dill_snorth.getBoreholeKeys()\n",
    "print(bkeys)\n",
    "\n",
    "i_bb_evnt = enorth.getIncCoords()\n",
    "loc_i_bb_evnt = enorth.getLocalIncCoords()\n",
    "o_bb_evnt = enorth.getExcCoords()\n",
    "all_bb_evnt = enorth.getOrigCoords()\n",
    "\n",
    "stations3 = dill_snorth.getIncludedStations(0,3)\n",
    "stations4 = dill_snorth.getIncludedStations(0,4)\n",
    "print('Station List:')\n",
    "'''\n",
    "for ist in range(len(stations3)):\n",
    "    scode3 = stations3[ist].code\n",
    "    #if scode3 == 'G054':\n",
    "        #stations3[ist].channels[0].depth = 180\n",
    "    print('stations[%d].%s:' %(ist,stations3[ist].code),vars(stations3[ist]))\n",
    "    print('stations3[%d].%s:' %(ist,stations3[ist].code),stations3[ist].channels[0].depth)\n",
    "    print('stations4[%d].%s:' %(ist,stations4[ist].code),stations4[ist].channels[0].depth)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "for ie in ekeys:\n",
    "    xy3 = dill_snorth.getIncStationCoords(ie,bkeys[0])\n",
    "    xy4 = dill_snorth.getIncStationCoords(ie,bkeys[0])\n",
    "    ex_xy3 = dill_snorth.getExcStationCoords(ie,bkeys[0])\n",
    "    er_xy3 = dill_snorth.getErrStationCoords(ie,bkeys[0])\n",
    "    ex_xy4 = dill_snorth.getExcStationCoords(ie,bkeys[1])\n",
    "    er_xy4 = dill_snorth.getErrStationCoords(ie,bkeys[1])\n",
    "\n",
    "    fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "    ax.scatter(i_bb_evnt[ie,0],i_bb_evnt[ie,1],s=80,c='red',marker='*',zorder=2)\n",
    "    ax.scatter(shape_xy[:,0],shape_xy[:,1],s=1,c='black',zorder=0)\n",
    "    ax.plot(gf_bbox.getCLoop()[:,0],gf_bbox.getCLoop()[:,1],c='green',zorder=1)\n",
    "    ax.scatter(xy3[:,0],xy3[:,1],s=50,c='blue',marker='v',zorder=3)\n",
    "    ax.scatter(xy4[:,0],xy4[:,1],s=100,c='gray',marker='o',zorder=2)\n",
    "    ax.scatter(ex_xy3[:,0],ex_xy3[:,1],s=80,c='yellow',marker='x',zorder=4)\n",
    "    ax.scatter(er_xy3[:,0],er_xy3[:,1],s=50,c='red',marker='v',zorder=4)\n",
    "    ax.scatter(ex_xy4[:,0],ex_xy4[:,1],s=100,c='black',marker='o',zorder=3)\n",
    "    ax.scatter(er_xy4[:,0],er_xy4[:,1],s=100,c='gray',marker='o',zorder=3)\n",
    "    otime = enorth[ie].origins[0].time\n",
    "    mag = enorth[ie].magnitudes[0].mag\n",
    "    title_str = 'EventMag: ' + str(mag) + ', Date/Time: ' + str(otime)\n",
    "    ax.set_title(title_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gnam.events.mtensors import mtensors\n",
    "import gnam.events.gstations\n",
    "import importlib\n",
    "importlib.reload(gnam.events.gstations)\n",
    "from gnam.specutils.write import write_stations as spec_ws\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.io.parsers.read_csv(\"event_moments.csv\",sep=\",\",index_col=0)\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "df = df.drop(columns=['ML','Latitude', 'Longitude', 'X-rd', 'Y-rd'])\n",
    "#df = df.drop(columns=['ML'])\n",
    "#print('ML, Lat, Lon, xrd, yrd')\n",
    "print('Column Names:',df.columns)\n",
    "print(df)\n",
    "\n",
    "#edates = df[['Date']].to_string()\n",
    "edates = df['Date'].to_numpy()\n",
    "print('type(edates):',type(edates))\n",
    "print('edates:',edates)\n",
    "print()\n",
    "\n",
    "gf_mts = mtensors('event_moments.csv')\n",
    "gf_df = gf_mts.get_df()\n",
    "print('gf_df:\\n',gf_df)\n",
    "print()\n",
    "utc_list = gf_mts.get_dates()\n",
    "print('utc_list:\\n',utc_list)\n",
    "\n",
    "ml_list = gf_mts.get_mags()\n",
    "print('ml_list:\\n',ml_list)\n",
    "\n",
    "print('gf_mts:\\n',gf_mts)\n",
    "print('len(gf_mts):',len(gf_mts))\n",
    "\n",
    "for imt in range(len(gf_mts)):\n",
    "    print('Tensor[%d]:' %(imt))\n",
    "    print(gf_mts[imt])\n",
    "    \n",
    "aki_bballs = gf_mts.get_aki_beachballs(diam=1700)\n",
    "cmt_bballs = gf_mts.get_cmt_beachballs(diam=1700,fc='red')\n",
    "print('num beachballs:',len(aki_bballs))\n",
    "print()\n",
    "aki_xc = gf_mts.get_xcoords()\n",
    "print('beachball xcoords:\\n',aki_xc)\n",
    "print()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "'''\n",
    "'''\n",
    "for ib in range(len(aki_bballs)):\n",
    "    ax.add_collection(aki_bballs[ib])\n",
    "#ax.add_collection(aki_bballs[3])\n",
    "#ax.add_collection(aki_bballs[2])\n",
    "ax.scatter(shape_xy[:,0],shape_xy[:,1],s=1,c='black',zorder=0)\n",
    "#ax.scatter(xy3[:,0],xy3[:,1],s=50,c='blue',marker='v',zorder=3)\n",
    "#ax.scatter(xy4[:,0],xy4[:,1],s=100,c='gray',marker='o',zorder=2)\n",
    "#ax.scatter(ex_xy3[:,0],ex_xy3[:,1],s=80,c='yellow',marker='x',zorder=4)\n",
    "#ax.scatter(er_xy3[:,0],er_xy3[:,1],s=50,c='red',marker='v',zorder=4)\n",
    "#ax.scatter(ex_xy4[:,0],ex_xy4[:,1],s=100,c='black',marker='o',zorder=3)\n",
    "#ax.scatter(er_xy4[:,0],er_xy4[:,1],s=100,c='gray',marker='o',zorder=3)\n",
    "ax.plot(gf_bbox.getCLoop()[:,0],gf_bbox.getCLoop()[:,1],c='green',zorder=0)\n",
    "ax.set_title('Field Shape')\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,figsize=(8,8))\n",
    "'''\n",
    "'''\n",
    "for ib in range(len(cmt_bballs)):\n",
    "    ax1.add_collection(cmt_bballs[ib])\n",
    "#ax1.add_collection(cmt_bballs[3])\n",
    "ax1.scatter(shape_xy[:,0],shape_xy[:,1],s=1,c='black',zorder=0)\n",
    "#ax1.scatter(xy3[:,0],xy3[:,1],s=50,c='blue',marker='v',zorder=3)\n",
    "#ax1.scatter(xy4[:,0],xy4[:,1],s=100,c='gray',marker='o',zorder=2)\n",
    "#ax1.scatter(ex_xy3[:,0],ex_xy3[:,1],s=80,c='yellow',marker='x',zorder=4)\n",
    "#ax1.scatter(er_xy3[:,0],er_xy3[:,1],s=50,c='red',marker='v',zorder=4)\n",
    "#ax1.scatter(ex_xy4[:,0],ex_xy4[:,1],s=100,c='black',marker='o',zorder=3)\n",
    "#ax1.scatter(er_xy4[:,0],er_xy4[:,1],s=100,c='gray',marker='o',zorder=3)\n",
    "ax1.plot(gf_bbox.getCLoop()[:,0],gf_bbox.getCLoop()[:,1],c='green',zorder=0)\n",
    "ax1.set_title('Field Shape')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "spec_ws('./stations_ipynb2',dill_snorth,0,(3,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnam.specutils.write import write_cmtsolution as spec_wcmt\n",
    "\n",
    "ie_cat = enorth.getIncCatalog()\n",
    "#ie_cat = ie_cat[-1]\n",
    "print(ie_cat[3].origins[0].time)\n",
    "ne = len(ie_cat)-1\n",
    "print('ne:',ne)\n",
    "gf_mts.update_utcdatetime(ie_cat)\n",
    "'''\n",
    "for im in range(len(gf_mts)):\n",
    "    ie = ne - im\n",
    "    print('ie:',ie)\n",
    "    print('ie_cat[%d][Date]: %s' %(im,ie_cat[ie].origins[0].time))\n",
    "    print('gf_mts[%d][Date]: %s' %(im,gf_mts[im]['Date']))\n",
    "'''\n",
    "e2mt_dict = gf_mts.map_events_2_tensors(ie_cat)\n",
    "e2mt_keys = e2mt_dict.keys()\n",
    "for key in e2mt_keys:\n",
    "    print('ie_cat[%d][Date]: %s' %(key,ie_cat[key].origins[0].time))\n",
    "    print('gf_mts[%d][Date]: %s' %(key,e2mt_dict[key]['Date']))\n",
    "    print('ie_cat[%d][Date]: %s' %(key,ie_cat[key].magnitudes[0].mag))\n",
    "    print('gf_mts[%d][Date]: %s' %(key,e2mt_dict[key]['ML']))\n",
    "    print()\n",
    "    \n",
    "\n",
    "spec_wcmt('./cmtsolutions_ipynb2',gf_mts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "e2mt_dict = gf_mts.map_events_2_tensors(ie_cat)\n",
    "e2mt_keys = e2mt_dict.keys()\n",
    "for ekey in e2mt_keys:\n",
    "    bkeys = dill_snorth.getBoreholeKeys()\n",
    "    bh_stat_list = []\n",
    "    for bkey in bkeys:\n",
    "        bh_stat_list.append(dill_snorth.getIncludedStations(ekey,bkey))\n",
    "    bh_stat_tup = tuple(bh_stat_list)   \n",
    "    exp_set = {'EKEY':ekey,'EVENT':ie_cat[ekey],'TENSOR':e2mt_dict[ekey],'STATIONS':bh_stat_tup}\n",
    "    experiments.append(exp_set)\n",
    "\n",
    "for eset in experiments:\n",
    "    fqn = 'tmp/'\n",
    "    pid = 'TAC'\n",
    "    nid = 'NL'\n",
    "    y = eset['EVENT'].origins[0].time.year\n",
    "    m = eset['EVENT'].origins[0].time.month\n",
    "    d = eset['EVENT'].origins[0].time.day\n",
    "    dname = '%s%s_%s_%s_%02d_%02d' %(fqn,pid,nid,y,m,d)\n",
    "    print('Experiment-%d:\\n'%(eset['EKEY']), dname)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = \"tmp/year/test\"\n",
    "\n",
    "# define the access rights\n",
    "access_rights = 0o755\n",
    "\n",
    "try:\n",
    "    os.makedirs(path, access_rights)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create directories and write CMTSOLUTION and STATION files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnam.specutils.write import write_cmtsolution as spec_wcmt\n",
    "from gnam.specutils.write import write_stations as spec_ws\n",
    "import os\n",
    "\n",
    "# define the access rights\n",
    "access_rights = 0o755\n",
    "\n",
    "for eset in experiments:\n",
    "    fqn = 'tmp/'\n",
    "    pid = 'TAC'\n",
    "    nid = 'NL'\n",
    "    y = eset['EVENT'].origins[0].time.year\n",
    "    m = eset['EVENT'].origins[0].time.month\n",
    "    d = eset['EVENT'].origins[0].time.day\n",
    "    dname = '%s%s_%s_%s_%02d_%02d/DATA' %(fqn,pid,nid,y,m,d)\n",
    "    print('Experiment-%d:\\n'%(eset['EKEY']), dname)\n",
    "    try:\n",
    "        os.makedirs(dname, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % dname)\n",
    "        print()\n",
    "    else:\n",
    "        bkeys = dill_snorth.getBoreholeKeys()\n",
    "        lxy = enorth.getLocalEventCoord(eset['EKEY'])\n",
    "        spec_wcmt(dname + '/CMTSOLUTION',eset['TENSOR'],lxy[0],lxy[1])\n",
    "        spec_ws(dname + '/STATIONS',dill_snorth,eset['EKEY'],bkeys)\n",
    "        print (\"Successfully created the directory %s\" % dname)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import Stream\n",
    "from obspy import Trace\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "e_st3 = dill_snorth.getStreamZ(3,3)\n",
    "e_st4 = dill_snorth.getStreamZ(3,4)\n",
    "\n",
    "e_st = e_st3 + e_st4\n",
    "\n",
    "e_st.filter('bandpass',freqmin=1.0,freqmax=18.0,corners=4)\n",
    "e_st.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lone = ['a','b','c']\n",
    "ltwo = [1,2,3]\n",
    "lthr = ['d',4,'e',5]\n",
    "mylist = []\n",
    "mylist.append(lone)\n",
    "mylist.append(ltwo)\n",
    "mylist.append(lthr)\n",
    "mytup = tuple(mylist)\n",
    "print(mytup)\n",
    "mytup[0][0]='z'\n",
    "print(mytup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_bb_evnt = enorth.getIncCoords()\n",
    "o_bb_evnt = enorth.getExcCoords()\n",
    "all_bb_evnt = enorth.getOrigCoords()\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "ax.scatter(i_bb_evnt[:,0],i_bb_evnt[:,1],s=80,c='red',marker='*',zorder=2)\n",
    "ax.scatter(shape_xy[:,0],shape_xy[:,1],s=1,c='black',zorder=0)\n",
    "ax.scatter(xy3[:,0],xy3[:,1],s=50,c='blue',marker='v',zorder=3)\n",
    "ax.scatter(xy4[:,0],xy4[:,1],s=100,c='gray',marker='o',zorder=2)\n",
    "ax.scatter(ex_xy3[:,0],ex_xy3[:,1],s=80,c='yellow',marker='x',zorder=4)\n",
    "ax.scatter(er_xy3[:,0],er_xy3[:,1],s=50,c='red',marker='v',zorder=4)\n",
    "ax.scatter(ex_xy4[:,0],ex_xy4[:,1],s=100,c='black',marker='o',zorder=3)\n",
    "ax.scatter(er_xy4[:,0],er_xy4[:,1],s=100,c='gray',marker='o',zorder=3)\n",
    "ax.plot(gf_bbox.getCLoop()[:,0],gf_bbox.getCLoop()[:,1],c='green',zorder=0)\n",
    "ax.set_title('Field Shape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "from obspy import Stream\n",
    "import time\n",
    "\n",
    "def test_run(cat):\n",
    "    stt = Stream()\n",
    "    for e in cat[1:2]:\n",
    "        t1 = e.origins[0].time\n",
    "        t2 = t1 + 16384//200 + 1\n",
    "        network = inventory[0]\n",
    "        for station in network:\n",
    "            try:\n",
    "                stt += client.get_waveforms(network.code, station.code, \"*\", \"HHZ\", \n",
    "                                           t1, t2)\n",
    "                                           #t1, t1 + 60, attach_response = True)\n",
    "                #print()\n",
    "                #print('Worked.  :',vars(station))\n",
    "                #stt.plot()\n",
    "            except:\n",
    "                pass\n",
    "                #print()\n",
    "                #print('Exception:',vars(station))\n",
    "                \n",
    "    return stt\n",
    "\n",
    "client = Client(\"KNMI\")\n",
    "stations = 'G0*4,G1*4,G2*4,G3*4,G4*4,G5*4,G6*4,G70*4'\n",
    "inventory = client.get_stations(network=\"NL\", station=stations , level=\"response\")\n",
    "\n",
    "ecat = enorth.getIncCatalog()\n",
    "print('Catalog:\\n',ecat)\n",
    "\n",
    "start = time.time()\n",
    "mystream = test_run(ecat)\n",
    "end = time.time()\n",
    "print('Time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "import shapefile as sf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "gron_sf = sf.Reader('FieldShapeFile/Groningen_field')\n",
    "print('gron_sf:',gron_sf)\n",
    "print('gron_sf.shapes():',gron_sf.shapes())\n",
    "gs = gron_sf.shape(0)\n",
    "\n",
    "gf_bb = gs.bbox\n",
    "print('gf_bb:',gf_bb)\n",
    "\n",
    "gf_pts = np.asarray(gs.points)\n",
    "\n",
    "lat = 53.283266 #picked form google maps just above Schildmeer\n",
    "lon = 6.813186  #picked form google maps just above Schildmeer\n",
    "\n",
    "wgs84_proj= Proj('epsg:4326')\n",
    "nl_proj = Proj('epsg:28992')\n",
    "\n",
    "x,y = transform(wgs84_proj,nl_proj,lat,lon)\n",
    "print('x,y = %f,%f' %(x,y))\n",
    "\n",
    "nlat,nlon = transform(nl_proj,wgs84_proj,x,y)\n",
    "print('olat,olon = %f,%f' %(lat,lon))\n",
    "print('nlat,nlon = %f,%f' %(nlat,nlon))\n",
    "\n",
    "#pbbox_x = np.array([mybbox[0],mybbox[0],mybbox[2],mybbox[2],mybbox[0]])\n",
    "#pbbox_y = np.array([mybbox[1],mybbox[3],mybbox[3],mybbox[1],mybbox[1]])\n",
    "\n",
    "#c_loop = np.array([[mybbox[0],mybbox[1]],[mybbox[0],mybbox[3]],\n",
    "                   #[mybbox[2],mybbox[3]],[mybbox[2],mybbox[1]],\n",
    "                   #[mybbox[0],mybbox[1]]])\n",
    "#\n",
    "#gf_bbox = bb(c_loop)\n",
    "plt_gfbb_x = np.array([gf_bb[0],gf_bb[2]])\n",
    "plt_gfbb_y = np.array([gf_bb[1],gf_bb[3]])\n",
    "\n",
    "xspan = plt_gfbb_x[1] - plt_gfbb_x[0]\n",
    "yspan = plt_gfbb_y[1] - plt_gfbb_y[0]\n",
    "llat,llon = transform(nl_proj,wgs84_proj,plt_gfbb_x[0]-xspan,plt_gfbb_y[0]-yspan)\n",
    "print('llat,llon = %f,%f' %(llat,llon))\n",
    "ulat,ulon = transform(nl_proj,wgs84_proj,plt_gfbb_x[1]+xspan,plt_gfbb_y[1]+yspan)\n",
    "print('ulat,ulon = %f,%f' %(ulat,ulon))\n",
    "\n",
    "lat0 = 0.5*(ulat-llat)\n",
    "lon0 = 0.5*(ulon-llon)\n",
    "\n",
    "lx,ly = transform(wgs84_proj,nl_proj,llat,llon)\n",
    "ux,uy = transform(wgs84_proj,nl_proj,ulat,ulon)\n",
    "\n",
    "map_gf = np.zeros(gf_pts.shape)\n",
    "print('gf_pts.shape:',gf_pts.shape)\n",
    "print('map_gf.shape:',map_gf.shape)\n",
    "\n",
    "for ic in range(len(gf_pts[:,0])):\n",
    "    ilat,ilon = transform(nl_proj,wgs84_proj,gf_pts[ic,0],gf_pts[ic,1])\n",
    "    map_gf[ic,0] = ilat\n",
    "    map_gf[ic,1] = ilon\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "ax.scatter(gf_pts[:,0],gf_pts[:,1],s=1,c='black',zorder=0)\n",
    "ax.scatter(plt_gfbb_x[0],plt_gfbb_y[0],s=80,c='red',marker='x',zorder=1)\n",
    "ax.scatter(plt_gfbb_x[1],plt_gfbb_y[1],s=80,c='red',marker='x',zorder=1)\n",
    "ax.scatter(lx,ly,s=40,c='gray',marker='o',zorder=1)\n",
    "ax.scatter(ux,uy,s=40,c='blue',marker='o',zorder=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "# setup Lambert Conformal basemap.\n",
    "m = Basemap(llcrnrlon=llon,llcrnrlat=llat,urcrnrlon=ulon,urcrnrlat=ulat,\n",
    "            resolution='h',projection='tmerc',lon_0=lon0,lat_0=lat0)\n",
    "#m = Basemap(width=12000000,height=9000000,projection='lcc',\n",
    "            #resolution='c',lat_1=45.,lat_2=55,lat_0=50,lon_0=-107.)\n",
    "# draw coastlines.\n",
    "m.drawcoastlines()\n",
    "# draw a boundary around the map, fill the background.\n",
    "# this background will end up being the ocean color, since\n",
    "# the continents will be drawn on top.\n",
    "m.drawmapboundary(fill_color='aqua')\n",
    "# fill continents, set lake color same as ocean color.\n",
    "m.fillcontinents(color='coral',lake_color='aqua')\n",
    "m.scatter(map_gf[:,0],map_fg[:,1])\n",
    "#m.bluemarble()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
